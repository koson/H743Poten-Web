{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b4d70dcf",
   "metadata": {},
   "source": [
    "# Peak Detection Functions Guide\n",
    "\n",
    "## üìñ Overview\n",
    "This notebook provides a comprehensive guide to the peak detection functions implemented in `src/routes/peak_detection.py`. The system includes multiple peak detection algorithms, baseline correction methods, and data processing utilities for cyclic voltammetry analysis.\n",
    "\n",
    "### üéØ Key Components:\n",
    "1. **Peak Detection Algorithms** - Multiple methods for detecting peaks\n",
    "2. **Baseline Correction** - Advanced baseline detection and correction\n",
    "3. **Data Processing** - File handling, normalization, and validation\n",
    "4. **API Endpoints** - Flask routes for web interface integration\n",
    "5. **Utility Functions** - Supporting functions for analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee63126",
   "metadata": {},
   "source": [
    "## 1. Peak Detection Algorithms üîç\n",
    "\n",
    "The system implements 7 different peak detection methods:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf86b872",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚Ä¢ prominence: Traditional prominence-based detection with enhanced baseline\n",
      "‚Ä¢ derivative: Derivative-based method using zero crossings\n",
      "‚Ä¢ ml: Machine Learning enhanced detection (DeepCV)\n",
      "‚Ä¢ enhanced_v3: Enhanced method version 3\n",
      "‚Ä¢ enhanced_v4: Enhanced method version 4\n",
      "‚Ä¢ enhanced_v4_improved: Improved version 4 with better filtering\n",
      "‚Ä¢ enhanced_v5: Latest enhanced method version 5\n"
     ]
    }
   ],
   "source": [
    "# Peak Detection Methods Available\n",
    "peak_detection_methods = {\n",
    "    'prominence': 'Traditional prominence-based detection with enhanced baseline',\n",
    "    'derivative': 'Derivative-based method using zero crossings',\n",
    "    'ml': 'Machine Learning enhanced detection (DeepCV)',\n",
    "    'enhanced_v3': 'Enhanced method version 3',\n",
    "    'enhanced_v4': 'Enhanced method version 4', \n",
    "    'enhanced_v4_improved': 'Improved version 4 with better filtering',\n",
    "    'enhanced_v5': 'Latest enhanced method version 5'\n",
    "}\n",
    "\n",
    "for method, description in peak_detection_methods.items():\n",
    "    print(f\"‚Ä¢ {method}: {description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f61662f2",
   "metadata": {},
   "source": [
    "### 1.1 Main Detection Function: `detect_cv_peaks()`\n",
    "\n",
    "```python\n",
    "def detect_cv_peaks(voltage, current, method='prominence'):\n",
    "    \"\"\"\n",
    "    Main dispatcher function for peak detection\n",
    "    \n",
    "    Parameters:\n",
    "    - voltage: numpy array of voltage values\n",
    "    - current: numpy array of current values\n",
    "    - method: string specifying detection method\n",
    "    \n",
    "    Returns:\n",
    "    - Dictionary with peaks list and metadata\n",
    "    \"\"\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da13565f",
   "metadata": {},
   "source": [
    "### 1.2 Prominence Method: `detect_peaks_prominence()`\n",
    "\n",
    "**Most commonly used method** combining traditional peak detection with advanced baseline correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4989c93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Load configuration settings (prominence threshold, peak width)\n",
      "2. Apply Enhanced Baseline Detector v2.1 or Voltage Window Detector v4\n",
      "3. Normalize current data for peak detection\n",
      "4. Find positive peaks (oxidation candidates)\n",
      "5. Find negative peaks (reduction candidates)\n",
      "6. Validate peaks using electrochemical rules\n",
      "7. Calculate peak characteristics (height, baseline current)\n",
      "8. Return formatted results with baseline data\n"
     ]
    }
   ],
   "source": [
    "# Prominence Method Workflow\n",
    "prominence_workflow = [\n",
    "    \"1. Load configuration settings (prominence threshold, peak width)\",\n",
    "    \"2. Apply Enhanced Baseline Detector v2.1 or Voltage Window Detector v4\", \n",
    "    \"3. Normalize current data for peak detection\",\n",
    "    \"4. Find positive peaks (oxidation candidates)\",\n",
    "    \"5. Find negative peaks (reduction candidates)\", \n",
    "    \"6. Validate peaks using electrochemical rules\",\n",
    "    \"7. Calculate peak characteristics (height, baseline current)\",\n",
    "    \"8. Return formatted results with baseline data\"\n",
    "]\n",
    "\n",
    "for i, step in enumerate(prominence_workflow, 1):\n",
    "    print(f\"{step}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bab6c744",
   "metadata": {},
   "source": [
    "#### Key Features of Prominence Method:\n",
    "\n",
    "- **Voltage Zone Validation**: Ensures peaks are in appropriate voltage ranges\n",
    "- **Current Direction Validation**: Oxidation peaks must have positive current, reduction peaks negative\n",
    "- **Peak Size Validation**: Filters out peaks below minimum height threshold\n",
    "- **Enhanced Baseline Correction**: Uses advanced algorithms for accurate baseline estimation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9185c15d",
   "metadata": {},
   "source": [
    "### 1.3 Derivative Method: `detect_peaks_derivative()`\n",
    "\n",
    "Uses mathematical derivatives to identify peak positions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bcb9931a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Derivative Method Steps:\n",
      "‚Ä¢ Smoothing: Apply Savitzky-Golay filter to reduce noise\n",
      "‚Ä¢ First Derivative: Calculate di/dv (slope)\n",
      "‚Ä¢ Second Derivative: Calculate d¬≤i/dv¬≤ (curvature)\n",
      "‚Ä¢ Zero Crossings: Find zero crossings in second derivative\n",
      "‚Ä¢ Filtering: Apply significance filters (height, prominence)\n",
      "‚Ä¢ Fallback: Use scipy.find_peaks if no peaks found\n"
     ]
    }
   ],
   "source": [
    "# Derivative Method Process\n",
    "derivative_process = {\n",
    "    'smoothing': 'Apply Savitzky-Golay filter to reduce noise',\n",
    "    'first_derivative': 'Calculate di/dv (slope)',\n",
    "    'second_derivative': 'Calculate d¬≤i/dv¬≤ (curvature)',\n",
    "    'zero_crossings': 'Find zero crossings in second derivative',\n",
    "    'filtering': 'Apply significance filters (height, prominence)',\n",
    "    'fallback': 'Use scipy.find_peaks if no peaks found'\n",
    "}\n",
    "\n",
    "print(\"Derivative Method Steps:\")\n",
    "for step, description in derivative_process.items():\n",
    "    print(f\"‚Ä¢ {step.replace('_', ' ').title()}: {description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99a97304",
   "metadata": {},
   "source": [
    "### 1.4 Machine Learning Method: `detect_peaks_ml()`\n",
    "\n",
    "**DeepCV Implementation** - Combines traditional methods with ML enhancement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9ca2a07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ML Method (DeepCV) Components:\n",
      "‚Ä¢ Base Detection: Start with prominence method for baseline peaks\n",
      "‚Ä¢ Feature Extraction: Extract 8 key features per peak\n",
      "‚Ä¢ Ml Enhancement: Apply neural network classification\n",
      "‚Ä¢ Confidence Scoring: Calculate ML-based confidence scores\n",
      "‚Ä¢ Validation: Apply electrochemical validation rules\n"
     ]
    }
   ],
   "source": [
    "# ML Method Architecture\n",
    "ml_architecture = {\n",
    "    'base_detection': 'Start with prominence method for baseline peaks',\n",
    "    'feature_extraction': 'Extract 8 key features per peak',\n",
    "    'ml_enhancement': 'Apply neural network classification',\n",
    "    'confidence_scoring': 'Calculate ML-based confidence scores',\n",
    "    'validation': 'Apply electrochemical validation rules'\n",
    "}\n",
    "\n",
    "print(\"ML Method (DeepCV) Components:\")\n",
    "for component, description in ml_architecture.items():\n",
    "    print(f\"‚Ä¢ {component.replace('_', ' ').title()}: {description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6dbca2c",
   "metadata": {},
   "source": [
    "#### ML Features Extracted:\n",
    "```python\n",
    "features = {\n",
    "    'peak_width': 'Full Width at Half Maximum (FWHM)',\n",
    "    'peak_symmetry': 'Left-right symmetry ratio', \n",
    "    'local_slope': 'Average slope in peak region',\n",
    "    'noise_level': 'Local noise estimation',\n",
    "    'baseline_quality': 'Quality of baseline fit',\n",
    "    'position_score': 'Electrochemical position validity',\n",
    "    'shape_factor': 'Peak shape characteristics',\n",
    "    'snr_estimate': 'Signal-to-noise ratio'\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc82df4e",
   "metadata": {},
   "source": [
    "## 2. Baseline Detection & Correction üìà\n",
    "\n",
    "Advanced baseline correction is crucial for accurate peak detection."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ad9bec",
   "metadata": {},
   "source": [
    "### 2.1 Voltage Window Baseline Detector v4\n",
    "\n",
    "**Primary Method** - Uses voltage windows to find stable baseline segments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4b7e095f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Voltage Window Baseline Detection Parameters:\n",
      "‚Ä¢ voltage_windows: [0.01, 0.02, 0.03, 0.05]\n",
      "‚Ä¢ r2_threshold: 0.95\n",
      "‚Ä¢ min_length: 5\n",
      "‚Ä¢ max_iterations: 1000\n",
      "‚Ä¢ skip_regions: Skip first 10% and last 5% (steep regions)\n"
     ]
    }
   ],
   "source": [
    "# Voltage Window Method Parameters\n",
    "voltage_window_params = {\n",
    "    'voltage_windows': [0.010, 0.020, 0.030, 0.050],  # 10-50 mV windows\n",
    "    'r2_threshold': 0.95,  # Minimum R¬≤ for linear segments\n",
    "    'min_length': 5,       # Minimum segment length\n",
    "    'max_iterations': 1000, # Computation limit\n",
    "    'skip_regions': 'Skip first 10% and last 5% (steep regions)'\n",
    "}\n",
    "\n",
    "print(\"Voltage Window Baseline Detection Parameters:\")\n",
    "for param, value in voltage_window_params.items():\n",
    "    print(f\"‚Ä¢ {param}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10308f13",
   "metadata": {},
   "source": [
    "### 2.2 Enhanced Baseline Detector v2.1\n",
    "\n",
    "**Fallback Method** - Traditional approach with improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d5044589",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Detect linear segments using detect_linear_segments()\n",
      "2. Find peak regions for baseline avoidance\n",
      "3. Select optimal segments for forward/reverse scans\n",
      "4. Score segments based on position and quality\n",
      "5. Generate baseline arrays for each scan direction\n",
      "6. Validate baseline quality and consistency\n"
     ]
    }
   ],
   "source": [
    "# Enhanced Baseline Workflow\n",
    "enhanced_baseline_steps = [\n",
    "    \"1. Detect linear segments using detect_linear_segments()\",\n",
    "    \"2. Find peak regions for baseline avoidance\", \n",
    "    \"3. Select optimal segments for forward/reverse scans\",\n",
    "    \"4. Score segments based on position and quality\",\n",
    "    \"5. Generate baseline arrays for each scan direction\",\n",
    "    \"6. Validate baseline quality and consistency\"\n",
    "]\n",
    "\n",
    "for step in enhanced_baseline_steps:\n",
    "    print(step)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "077c0f7f",
   "metadata": {},
   "source": [
    "### 2.3 Critical Baseline Functions\n",
    "\n",
    "#### `detect_linear_segments()`\n",
    "Finds all potential baseline segments using voltage windows.\n",
    "\n",
    "#### `detect_improved_baseline_2step()`\n",
    "Two-step process: find segments, then select best ones for each scan direction.\n",
    "\n",
    "#### Segment Scoring\n",
    "```python\n",
    "def score_baseline_segment(segment, scan_direction):\n",
    "    score = segment['r2'] * 100  # Base R¬≤ score\n",
    "    score += stability_score      # Low std deviation bonus\n",
    "    score += position_score       # Correct position for scan direction\n",
    "    score += slope_penalty        # Penalty for steep slopes\n",
    "    return score\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c66825",
   "metadata": {},
   "source": [
    "## 3. Data Processing Functions üîß"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cde85998",
   "metadata": {},
   "source": [
    "### 3.1 File Loading Functions\n",
    "\n",
    "#### `load_csv_file(file_path)`\n",
    "- Handles multiple CSV formats (Palmsens, PiPot, STM32)\n",
    "- Automatic header detection\n",
    "- Unit conversion (mA, ¬µA, nA to ¬µA)\n",
    "- Data validation and error handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44400037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Supported Instrument File Formats:\n",
      "\n",
      "PALMSENS:\n",
      "  ‚Ä¢ headers: ['V', 'A']\n",
      "  ‚Ä¢ units: Usually Amperes (A)\n",
      "  ‚Ä¢ format: Standard CSV with headers\n",
      "\n",
      "PIPOT:\n",
      "  ‚Ä¢ headers: ['FileName:', 'V', 'uA']\n",
      "  ‚Ä¢ units: microAmps (¬µA)\n",
      "  ‚Ä¢ format: Instrument format with filename header\n",
      "\n",
      "STM32:\n",
      "  ‚Ä¢ headers: ['voltage', 'current']\n",
      "  ‚Ä¢ units: Various (auto-detected)\n",
      "  ‚Ä¢ format: Standard CSV\n"
     ]
    }
   ],
   "source": [
    "# Supported File Formats\n",
    "file_formats = {\n",
    "    'palmsens': {\n",
    "        'headers': ['V', 'A'] or ['voltage', 'current'],\n",
    "        'units': 'Usually Amperes (A)',\n",
    "        'format': 'Standard CSV with headers'\n",
    "    },\n",
    "    'pipot': {\n",
    "        'headers': ['FileName:', 'V', 'uA'],\n",
    "        'units': 'microAmps (¬µA)', \n",
    "        'format': 'Instrument format with filename header'\n",
    "    },\n",
    "    'stm32': {\n",
    "        'headers': ['voltage', 'current'],\n",
    "        'units': 'Various (auto-detected)',\n",
    "        'format': 'Standard CSV'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Supported Instrument File Formats:\")\n",
    "for instrument, details in file_formats.items():\n",
    "    print(f\"\\n{instrument.upper()}:\")\n",
    "    for key, value in details.items():\n",
    "        print(f\"  ‚Ä¢ {key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b15b594",
   "metadata": {},
   "source": [
    "### 3.2 Sample Information Extraction\n",
    "\n",
    "#### `extract_sample_info_from_filename(filename)`\n",
    "Extracts metadata from filename patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da70d443",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename Pattern Recognition:\n",
      "\n",
      "Concentration:\n",
      "  ‚Ä¢ 5.0mM: Decimal format (5.0mm)\n",
      "  ‚Ä¢ 5_0mM: Underscore format (5_0mm)\n",
      "  ‚Ä¢ 0_5mM: Decimal underscore (0_5mm for 0.5mM)\n",
      "  ‚Ä¢ 5mM: Simple integer (5mm)\n",
      "\n",
      "Scan_Rate:\n",
      "  ‚Ä¢ 100mVpS: Standard format (100mVpS)\n",
      "  ‚Ä¢ 100mvps: Lowercase variant\n",
      "  ‚Ä¢ 100_mV_s: Underscore separated\n",
      "\n",
      "Instrument:\n",
      "  ‚Ä¢ palmsens_: Palmsens files\n",
      "  ‚Ä¢ pipot_ferro_: PiPot Ferro files\n",
      "  ‚Ä¢ stm32_: STM32 files\n"
     ]
    }
   ],
   "source": [
    "# Filename Pattern Examples\n",
    "filename_patterns = {\n",
    "    'concentration': {\n",
    "        '5.0mM': 'Decimal format (5.0mm)',\n",
    "        '5_0mM': 'Underscore format (5_0mm)', \n",
    "        '0_5mM': 'Decimal underscore (0_5mm for 0.5mM)',\n",
    "        '5mM': 'Simple integer (5mm)'\n",
    "    },\n",
    "    'scan_rate': {\n",
    "        '100mVpS': 'Standard format (100mVpS)',\n",
    "        '100mvps': 'Lowercase variant',\n",
    "        '100_mV_s': 'Underscore separated'\n",
    "    },\n",
    "    'instrument': {\n",
    "        'palmsens_': 'Palmsens files',\n",
    "        'pipot_ferro_': 'PiPot Ferro files',\n",
    "        'stm32_': 'STM32 files'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Filename Pattern Recognition:\")\n",
    "for category, patterns in filename_patterns.items():\n",
    "    print(f\"\\n{category.title()}:\")\n",
    "    for pattern, description in patterns.items():\n",
    "        print(f\"  ‚Ä¢ {pattern}: {description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fd64b46",
   "metadata": {},
   "source": [
    "### 3.3 Analysis Session Management\n",
    "\n",
    "#### In-Memory Storage\n",
    "```python\n",
    "analysis_sessions = {}  # Global session storage\n",
    "\n",
    "def create_analysis_session():\n",
    "    session_id = str(uuid.uuid4())\n",
    "    analysis_sessions[session_id] = {\n",
    "        'peaks': peak_data,\n",
    "        'data': trace_data, \n",
    "        'method': detection_method,\n",
    "        'created_at': timestamp\n",
    "    }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de9236f",
   "metadata": {},
   "source": [
    "## 4. API Endpoints üåê\n",
    "\n",
    "Flask routes providing web interface integration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "174bc766",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Endpoints:\n",
      "‚Ä¢ GET  /api/get_saved_files                - List all saved CSV files\n",
      "‚Ä¢ GET  /api/load_saved_file_by_name/<filename> - Load specific CSV file\n",
      "‚Ä¢ POST /get-peaks/<method>                 - Detect peaks using specified method\n",
      "‚Ä¢ GET  /get-progress                       - Get peak detection progress\n",
      "‚Ä¢ GET  /get-settings                       - Get current detection settings\n",
      "‚Ä¢ POST /update-settings                    - Update detection parameters\n",
      "‚Ä¢ POST /create_analysis_session            - Create new analysis session\n",
      "‚Ä¢ GET  /peak_analysis/<session_id>         - Render analysis results page\n"
     ]
    }
   ],
   "source": [
    "# API Endpoints Overview\n",
    "api_endpoints = {\n",
    "    'GET /api/get_saved_files': 'List all saved CSV files',\n",
    "    'GET /api/load_saved_file_by_name/<filename>': 'Load specific CSV file',\n",
    "    'POST /get-peaks/<method>': 'Detect peaks using specified method',\n",
    "    'GET /get-progress': 'Get peak detection progress',\n",
    "    'GET /get-settings': 'Get current detection settings',\n",
    "    'POST /update-settings': 'Update detection parameters',\n",
    "    'POST /create_analysis_session': 'Create new analysis session',\n",
    "    'GET /peak_analysis/<session_id>': 'Render analysis results page'\n",
    "}\n",
    "\n",
    "print(\"API Endpoints:\")\n",
    "for endpoint, description in api_endpoints.items():\n",
    "    method = endpoint.split(' ')[0]\n",
    "    route = endpoint.split(' ')[1]\n",
    "    print(f\"‚Ä¢ {method:4} {route:35} - {description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ee01cc0",
   "metadata": {},
   "source": [
    "### 4.1 Main Peak Detection Endpoint\n",
    "\n",
    "#### `POST /get-peaks/<method>`\n",
    "**Primary endpoint** for peak detection analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b7d0ed6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Peak Detection Endpoint Process:\n",
      "‚Ä¢ Input Validation: Validate method and request data\n",
      "‚Ä¢ Progress Init: Initialize progress tracking\n",
      "‚Ä¢ Data Processing: Handle single/multi-trace data\n",
      "‚Ä¢ Peak Detection: Call appropriate detection method\n",
      "‚Ä¢ Result Formatting: Format results for JSON response\n",
      "‚Ä¢ Logging: Optional save to parameter log\n",
      "‚Ä¢ Progress Complete: Mark detection as complete\n"
     ]
    }
   ],
   "source": [
    "# Peak Detection Endpoint Workflow\n",
    "endpoint_workflow = {\n",
    "    'input_validation': 'Validate method and request data',\n",
    "    'progress_init': 'Initialize progress tracking',\n",
    "    'data_processing': 'Handle single/multi-trace data',\n",
    "    'peak_detection': 'Call appropriate detection method',\n",
    "    'result_formatting': 'Format results for JSON response',\n",
    "    'logging': 'Optional save to parameter log',\n",
    "    'progress_complete': 'Mark detection as complete'\n",
    "}\n",
    "\n",
    "print(\"Peak Detection Endpoint Process:\")\n",
    "for step, description in endpoint_workflow.items():\n",
    "    print(f\"‚Ä¢ {step.replace('_', ' ').title()}: {description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874f346e",
   "metadata": {},
   "source": [
    "### 4.2 Progress Tracking\n",
    "\n",
    "Real-time progress monitoring for long-running analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "27433810",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress Tracking Fields:\n",
      "‚Ä¢ active: Boolean - whether detection is running\n",
      "‚Ä¢ current_file: Current file number being processed\n",
      "‚Ä¢ total_files: Total number of files to process\n",
      "‚Ä¢ percent: Completion percentage (0-100)\n",
      "‚Ä¢ message: Current status message\n",
      "‚Ä¢ start_time: Processing start timestamp\n",
      "‚Ä¢ elapsed_time: Time elapsed since start\n"
     ]
    }
   ],
   "source": [
    "# Progress Tracking Structure\n",
    "progress_structure = {\n",
    "    'active': 'Boolean - whether detection is running',\n",
    "    'current_file': 'Current file number being processed',\n",
    "    'total_files': 'Total number of files to process',\n",
    "    'percent': 'Completion percentage (0-100)',\n",
    "    'message': 'Current status message',\n",
    "    'start_time': 'Processing start timestamp',\n",
    "    'elapsed_time': 'Time elapsed since start'\n",
    "}\n",
    "\n",
    "print(\"Progress Tracking Fields:\")\n",
    "for field, description in progress_structure.items():\n",
    "    print(f\"‚Ä¢ {field}: {description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "108cad06",
   "metadata": {},
   "source": [
    "## 5. Utility Functions ‚öôÔ∏è"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d355dcb0",
   "metadata": {},
   "source": [
    "### 5.1 Data Validation\n",
    "\n",
    "#### `ensure_json_serializable(data)`\n",
    "Ensures all data can be serialized to JSON (converts numpy types, handles NaN/Inf).\n",
    "\n",
    "#### Peak Validation Rules\n",
    "```python\n",
    "def validate_peak_pre_detection(voltage_val, current_val, peak_type):\n",
    "    # Voltage zone validation\n",
    "    if peak_type == 'oxidation':\n",
    "        if not (OX_VOLTAGE_MIN <= voltage_val <= OX_VOLTAGE_MAX):\n",
    "            return False\n",
    "    \n",
    "    # Current direction validation  \n",
    "    if peak_type == 'oxidation' and current_val < 0:\n",
    "        return False\n",
    "        \n",
    "    # Peak size validation\n",
    "    if abs(current_val) < MIN_PEAK_HEIGHT:\n",
    "        return False\n",
    "        \n",
    "    return True\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27209294",
   "metadata": {},
   "source": [
    "### 5.2 Parameter Logging\n",
    "\n",
    "#### `save_analysis_to_log(voltage, current, peaks, metadata)`\n",
    "Saves analysis results to database for later review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d6f23a52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database Logging Structure:\n",
      "\n",
      "Measurement Data:\n",
      "  ‚Ä¢ sample_id: Unique sample identifier\n",
      "  ‚Ä¢ instrument_type: palmsens/pipot/stm32\n",
      "  ‚Ä¢ timestamp: Analysis timestamp\n",
      "  ‚Ä¢ scan_rate: mV/s scan rate\n",
      "  ‚Ä¢ voltage_range: Min/max voltage values\n",
      "  ‚Ä¢ data_points: Number of data points\n",
      "  ‚Ä¢ user_notes: Optional user annotations\n",
      "\n",
      "Peak Data:\n",
      "  ‚Ä¢ type: oxidation/reduction\n",
      "  ‚Ä¢ voltage: Peak potential\n",
      "  ‚Ä¢ current: Peak current\n",
      "  ‚Ä¢ height: Peak height from baseline\n",
      "  ‚Ä¢ baseline_info: Baseline calculation details\n",
      "  ‚Ä¢ enabled: User selection status\n"
     ]
    }
   ],
   "source": [
    "# Logged Data Structure\n",
    "logged_data = {\n",
    "    'measurement_data': {\n",
    "        'sample_id': 'Unique sample identifier',\n",
    "        'instrument_type': 'palmsens/pipot/stm32',\n",
    "        'timestamp': 'Analysis timestamp',\n",
    "        'scan_rate': 'mV/s scan rate',\n",
    "        'voltage_range': 'Min/max voltage values',\n",
    "        'data_points': 'Number of data points',\n",
    "        'user_notes': 'Optional user annotations'\n",
    "    },\n",
    "    'peak_data': {\n",
    "        'type': 'oxidation/reduction',\n",
    "        'voltage': 'Peak potential',\n",
    "        'current': 'Peak current', \n",
    "        'height': 'Peak height from baseline',\n",
    "        'baseline_info': 'Baseline calculation details',\n",
    "        'enabled': 'User selection status'\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Database Logging Structure:\")\n",
    "for category, fields in logged_data.items():\n",
    "    print(f\"\\n{category.replace('_', ' ').title()}:\")\n",
    "    for field, description in fields.items():\n",
    "        print(f\"  ‚Ä¢ {field}: {description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4347ebc9",
   "metadata": {},
   "source": [
    "## 6. Configuration & Settings ‚öôÔ∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "53651df4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Default Configuration Settings:\n",
      "‚Ä¢ PEAK_PROMINENCE: 0.1\n",
      "‚Ä¢ PEAK_WIDTH: 5\n",
      "‚Ä¢ MIN_PEAK_HEIGHT: 1.0\n",
      "‚Ä¢ OX_VOLTAGE_RANGE: (-0.3, 0.8)\n",
      "‚Ä¢ RED_VOLTAGE_RANGE: (-0.8, 0.4)\n",
      "‚Ä¢ R2_THRESHOLD: 0.95\n",
      "‚Ä¢ MAX_ITERATIONS: 1000\n"
     ]
    }
   ],
   "source": [
    "# Default Configuration Settings\n",
    "default_settings = {\n",
    "    'PEAK_PROMINENCE': 0.1,    # Minimum peak prominence (normalized)\n",
    "    'PEAK_WIDTH': 5,           # Minimum peak width in data points\n",
    "    'MIN_PEAK_HEIGHT': 1.0,    # Minimum peak height (¬µA)\n",
    "    'OX_VOLTAGE_RANGE': (-0.3, 0.8),   # Oxidation voltage range (V)\n",
    "    'RED_VOLTAGE_RANGE': (-0.8, 0.4),  # Reduction voltage range (V)\n",
    "    'R2_THRESHOLD': 0.95,      # Minimum R¬≤ for baseline segments\n",
    "    'MAX_ITERATIONS': 1000     # Maximum iterations for baseline detection\n",
    "}\n",
    "\n",
    "print(\"Default Configuration Settings:\")\n",
    "for setting, value in default_settings.items():\n",
    "    print(f\"‚Ä¢ {setting}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9322df",
   "metadata": {},
   "source": [
    "## 7. Error Handling & Fallbacks üõ°Ô∏è"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "274ad275",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error Handling & Fallback Mechanisms:\n",
      "‚Ä¢ Scipy Fallback: If SciPy not available, use simple implementations\n",
      "‚Ä¢ Baseline Fallback: Multiple baseline methods with fallback chain\n",
      "‚Ä¢ Peak Fallback: Simple peak detection if advanced methods fail\n",
      "‚Ä¢ Data Validation: Check for NaN/Inf values and handle gracefully\n",
      "‚Ä¢ File Format: Flexible parsing for different instrument formats\n",
      "‚Ä¢ Memory Management: Chunk processing for large datasets\n",
      "‚Ä¢ Timeout Protection: Maximum iteration limits to prevent hangs\n"
     ]
    }
   ],
   "source": [
    "# Error Handling Strategy\n",
    "error_handling = {\n",
    "    'scipy_fallback': 'If SciPy not available, use simple implementations',\n",
    "    'baseline_fallback': 'Multiple baseline methods with fallback chain',\n",
    "    'peak_fallback': 'Simple peak detection if advanced methods fail',\n",
    "    'data_validation': 'Check for NaN/Inf values and handle gracefully',\n",
    "    'file_format': 'Flexible parsing for different instrument formats',\n",
    "    'memory_management': 'Chunk processing for large datasets',\n",
    "    'timeout_protection': 'Maximum iteration limits to prevent hangs'\n",
    "}\n",
    "\n",
    "print(\"Error Handling & Fallback Mechanisms:\")\n",
    "for mechanism, description in error_handling.items():\n",
    "    print(f\"‚Ä¢ {mechanism.replace('_', ' ').title()}: {description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2c1a2b",
   "metadata": {},
   "source": [
    "## 8. Performance Considerations üöÄ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0ca07c1c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Performance Optimization Strategies:\n",
      "‚Ä¢ Vectorized Operations: Use NumPy vectorized operations where possible\n",
      "‚Ä¢ Early Termination: Stop processing when sufficient quality reached\n",
      "‚Ä¢ Adaptive Windowing: Adjust window sizes based on data characteristics\n",
      "‚Ä¢ Memory Efficiency: Avoid unnecessary data copies\n",
      "‚Ä¢ Caching: Cache computed baselines and intermediate results\n",
      "‚Ä¢ Parallel Processing: Process multiple files concurrently\n",
      "‚Ä¢ Progress Tracking: Provide user feedback for long operations\n"
     ]
    }
   ],
   "source": [
    "# Performance Optimizations\n",
    "optimizations = {\n",
    "    'vectorized_operations': 'Use NumPy vectorized operations where possible',\n",
    "    'early_termination': 'Stop processing when sufficient quality reached',\n",
    "    'adaptive_windowing': 'Adjust window sizes based on data characteristics',\n",
    "    'memory_efficiency': 'Avoid unnecessary data copies',\n",
    "    'caching': 'Cache computed baselines and intermediate results',\n",
    "    'parallel_processing': 'Process multiple files concurrently',\n",
    "    'progress_tracking': 'Provide user feedback for long operations'\n",
    "}\n",
    "\n",
    "print(\"Performance Optimization Strategies:\")\n",
    "for strategy, description in optimizations.items():\n",
    "    print(f\"‚Ä¢ {strategy.replace('_', ' ').title()}: {description}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bd44961",
   "metadata": {},
   "source": [
    "## 9. Usage Examples üí°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "738918fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Example CV data created:\n",
      "‚Ä¢ Voltage range: -0.50 to 0.50 V\n",
      "‚Ä¢ Current range: -3.17 to 5.10 ¬µA\n",
      "‚Ä¢ Data points: 1000\n"
     ]
    }
   ],
   "source": [
    "# Example: Basic Peak Detection\n",
    "import numpy as np\n",
    "\n",
    "# Simulated CV data\n",
    "voltage = np.linspace(-0.5, 0.5, 1000)\n",
    "current = np.random.normal(0, 0.1, 1000)  # Base noise\n",
    "\n",
    "# Add synthetic peaks\n",
    "# Oxidation peak at +0.2V\n",
    "ox_peak = np.exp(-((voltage - 0.2) / 0.05)**2) * 5.0\n",
    "# Reduction peak at -0.2V  \n",
    "red_peak = -np.exp(-((voltage + 0.2) / 0.05)**2) * 3.0\n",
    "\n",
    "current += ox_peak + red_peak\n",
    "\n",
    "print(\"Example CV data created:\")\n",
    "print(f\"‚Ä¢ Voltage range: {voltage.min():.2f} to {voltage.max():.2f} V\")\n",
    "print(f\"‚Ä¢ Current range: {current.min():.2f} to {current.max():.2f} ¬µA\")\n",
    "print(f\"‚Ä¢ Data points: {len(voltage)}\")\n",
    "\n",
    "# This data could be passed to detect_cv_peaks(voltage, current, method='prominence')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dec85f2",
   "metadata": {},
   "source": [
    "## 10. Troubleshooting Guide üîß"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "87b03ec0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Troubleshooting Guide:\n",
      "\n",
      "No Peaks Detected:\n",
      "  Causes: Prominence threshold too high, Poor baseline correction, Noisy data\n",
      "  Solutions: Lower prominence threshold, Try different baseline method, Apply smoothing\n",
      "\n",
      "False Positives:\n",
      "  Causes: Prominence threshold too low, Baseline artifacts, Noise spikes\n",
      "  Solutions: Increase prominence threshold, Improve baseline correction, Filter noise\n",
      "\n",
      "Baseline Errors:\n",
      "  Causes: Insufficient linear segments, Peak interference, Data quality issues\n",
      "  Solutions: Adjust R¬≤ threshold, Use peak avoidance, Check data quality\n",
      "\n",
      "Processing Slow:\n",
      "  Causes: Large datasets, Complex baseline detection, Multiple files\n",
      "  Solutions: Reduce max iterations, Use simpler methods, Process in chunks\n"
     ]
    }
   ],
   "source": [
    "# Common Issues and Solutions\n",
    "troubleshooting = {\n",
    "    'no_peaks_detected': {\n",
    "        'causes': ['Prominence threshold too high', 'Poor baseline correction', 'Noisy data'],\n",
    "        'solutions': ['Lower prominence threshold', 'Try different baseline method', 'Apply smoothing']\n",
    "    },\n",
    "    'false_positives': {\n",
    "        'causes': ['Prominence threshold too low', 'Baseline artifacts', 'Noise spikes'],\n",
    "        'solutions': ['Increase prominence threshold', 'Improve baseline correction', 'Filter noise']\n",
    "    },\n",
    "    'baseline_errors': {\n",
    "        'causes': ['Insufficient linear segments', 'Peak interference', 'Data quality issues'],\n",
    "        'solutions': ['Adjust R¬≤ threshold', 'Use peak avoidance', 'Check data quality']\n",
    "    },\n",
    "    'processing_slow': {\n",
    "        'causes': ['Large datasets', 'Complex baseline detection', 'Multiple files'],\n",
    "        'solutions': ['Reduce max iterations', 'Use simpler methods', 'Process in chunks']\n",
    "    }\n",
    "}\n",
    "\n",
    "print(\"Troubleshooting Guide:\")\n",
    "for issue, details in troubleshooting.items():\n",
    "    print(f\"\\n{issue.replace('_', ' ').title()}:\")\n",
    "    print(f\"  Causes: {', '.join(details['causes'])}\")\n",
    "    print(f\"  Solutions: {', '.join(details['solutions'])}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b816132a",
   "metadata": {},
   "source": [
    "## üìö Summary\n",
    "\n",
    "The `peak_detection.py` module provides a comprehensive system for cyclic voltammetry analysis with:\n",
    "\n",
    "‚úÖ **7 different peak detection algorithms**  \n",
    "‚úÖ **Advanced baseline correction methods**  \n",
    "‚úÖ **Robust error handling and fallbacks**  \n",
    "‚úÖ **Web API integration**  \n",
    "‚úÖ **Multi-format file support**  \n",
    "‚úÖ **Real-time progress tracking**  \n",
    "‚úÖ **Parameter logging and session management**  \n",
    "\n",
    "### Key Strengths:\n",
    "- **Flexibility**: Multiple algorithms for different use cases\n",
    "- **Reliability**: Extensive error handling and validation\n",
    "- **Performance**: Optimized for real-time analysis\n",
    "- **Integration**: Seamless web interface support\n",
    "\n",
    "### Recommended Usage:\n",
    "1. **Start with prominence method** for most applications\n",
    "2. **Use ML method** for enhanced accuracy when trained\n",
    "3. **Try derivative method** for noisy or complex data\n",
    "4. **Adjust settings** based on your specific requirements"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
