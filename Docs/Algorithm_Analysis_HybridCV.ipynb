{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1e01bae",
   "metadata": {},
   "source": [
    "# HybridCV Algorithm Analysis\n",
    "## Derivative-Based Peak Detection for Cyclic Voltammetry\n",
    "\n",
    "---\n",
    "\n",
    "### Overview\n",
    "The **HybridCV** algorithm combines derivative-based signal analysis with traditional peak detection methods. It uses **first and second derivative analysis** to identify peak locations through zero-crossing detection, providing a mathematical approach to peak identification.\n",
    "\n",
    "### Key Features\n",
    "- **Derivative analysis**: Uses first and second derivatives for peak identification\n",
    "- **Zero-crossing detection**: Locates peaks via second derivative zero crossings\n",
    "- **Adaptive filtering**: Savitzky-Golay smoothing for noise reduction\n",
    "- **Hybrid approach**: Combines mathematical rigor with practical robustness\n",
    "- **Fallback mechanisms**: Multiple detection strategies for reliability\n",
    "\n",
    "### Research Applications\n",
    "This algorithm excels in:\n",
    "- Mathematical analysis of CV peak shapes\n",
    "- Detection of subtle or shoulder peaks\n",
    "- Noisy data requiring sophisticated filtering\n",
    "- Research requiring mathematical peak characterization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0d6bce0",
   "metadata": {},
   "source": [
    "## Algorithm Theory and Implementation\n",
    "\n",
    "### 1. Mathematical Foundation: Derivative Analysis\n",
    "\n",
    "The HybridCV algorithm is based on the mathematical principle that **peaks correspond to critical points** in the current-voltage relationship:\n",
    "\n",
    "#### First Derivative (Slope)\n",
    "```python\n",
    "dI/dV = slope = gradient(current) / gradient(voltage)\n",
    "```\n",
    "- **Positive slope**: Current increasing with voltage\n",
    "- **Zero slope**: Peak or valley (critical point)\n",
    "- **Negative slope**: Current decreasing with voltage\n",
    "\n",
    "#### Second Derivative (Curvature)\n",
    "```python\n",
    "d¬≤I/dV¬≤ = gradient(slope)\n",
    "```\n",
    "- **Zero crossing (+ to -)**: Peak maximum\n",
    "- **Zero crossing (- to +)**: Peak minimum\n",
    "- **Magnitude**: Peak sharpness indicator\n",
    "\n",
    "### 2. Signal Processing Pipeline\n",
    "\n",
    "#### Step 1: Data Smoothing\n",
    "**Savitzky-Golay Filter**: Preserves peak shape while reducing noise\n",
    "```python\n",
    "# Adaptive window size based on data length\n",
    "window_length = min(11, len(current) // 10)\n",
    "if window_length % 2 == 0: window_length += 1  # Must be odd\n",
    "current_smooth = savgol_filter(current, window_length, 3)\n",
    "```\n",
    "\n",
    "#### Step 2: Derivative Calculation\n",
    "```python\n",
    "# First derivative (slope)\n",
    "dv = np.gradient(voltage)\n",
    "di = np.gradient(current_smooth)\n",
    "slope = di / dv\n",
    "\n",
    "# Second derivative (curvature)\n",
    "d2i = np.gradient(slope)\n",
    "```\n",
    "\n",
    "#### Step 3: Zero-Crossing Detection\n",
    "```python\n",
    "# Find where second derivative changes sign\n",
    "zero_crossings = np.where(np.diff(np.signbit(d2i)))[0]\n",
    "```\n",
    "\n",
    "### 3. Peak Validation and Filtering\n",
    "\n",
    "#### Adaptive Thresholds\n",
    "- **Minimum peak height**: Based on data statistics\n",
    "- **Prominence requirement**: Peak must stand out from surroundings\n",
    "- **Width constraints**: Reasonable peak width limits\n",
    "\n",
    "#### Statistical Analysis\n",
    "```python\n",
    "current_std = np.std(current)\n",
    "current_range = np.max(current) - np.min(current)\n",
    "min_peak_height = max(current_std * 0.2, current_range * 0.01)\n",
    "min_prominence = max(current_std * 0.1, current_range * 0.005)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "586adac4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries for HybridCV analysis\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from scipy.signal import find_peaks, savgol_filter\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "from typing import List, Dict, Tuple, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"viridis\")\n",
    "\n",
    "print(\"‚úÖ Libraries imported successfully\")\n",
    "print(\"üî¨ Ready for HybridCV algorithm analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "591a8f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridCVDetector:\n",
    "    \"\"\"\n",
    "    HybridCV Peak Detection Algorithm\n",
    "    Derivative-based approach with adaptive filtering and validation\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, smoothing_window=None, noise_factor=0.2, prominence_factor=0.1):\n",
    "        self.smoothing_window = smoothing_window  # Auto-calculated if None\n",
    "        self.noise_factor = noise_factor          # For adaptive thresholding\n",
    "        self.prominence_factor = prominence_factor # For prominence calculation\n",
    "        \n",
    "    def detect_peaks_derivative(self, voltage: np.ndarray, current: np.ndarray) -> Dict:\n",
    "        \"\"\"\n",
    "        Main HybridCV detection method using derivative analysis\n",
    "        \n",
    "        Args:\n",
    "            voltage: Voltage array (V)\n",
    "            current: Current array (¬µA)\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary containing peaks and metadata\n",
    "        \"\"\"\n",
    "        print(f\"üî¨ HybridCV Analysis: Processing {len(voltage)} data points\")\n",
    "        print(f\"üìä Data range - V: {voltage.min():.3f} to {voltage.max():.3f}V\")\n",
    "        print(f\"üìä Data range - I: {current.min():.3f} to {current.max():.3f}¬µA\")\n",
    "        \n",
    "        # Step 1: Data smoothing with adaptive window\n",
    "        print(\"\\nüîß Step 1: Adaptive Data Smoothing\")\n",
    "        current_smooth = self._smooth_data(current)\n",
    "        \n",
    "        # Step 2: Derivative calculation\n",
    "        print(\"\\nüìê Step 2: Derivative Analysis\")\n",
    "        derivatives = self._calculate_derivatives(voltage, current_smooth)\n",
    "        \n",
    "        # Step 3: Zero-crossing detection\n",
    "        print(\"\\nüéØ Step 3: Zero-Crossing Detection\")\n",
    "        zero_crossings = self._detect_zero_crossings(derivatives['second_derivative'])\n",
    "        \n",
    "        # Step 4: Peak validation and filtering\n",
    "        print(\"\\n‚úÖ Step 4: Peak Validation and Filtering\")\n",
    "        peaks = self._validate_and_filter_peaks(\n",
    "            zero_crossings, voltage, current, current_smooth, derivatives\n",
    "        )\n",
    "        \n",
    "        # Step 5: Fallback detection if no peaks found\n",
    "        if len(peaks) == 0:\n",
    "            print(\"\\nüîÑ Step 5: Fallback Detection\")\n",
    "            peaks = self._fallback_detection(voltage, current)\n",
    "        \n",
    "        # Step 6: Final classification\n",
    "        print(\"\\nüè∑Ô∏è Step 6: Peak Classification\")\n",
    "        classified_peaks = self._classify_peaks(peaks)\n",
    "        \n",
    "        print(f\"\\n‚úÖ HybridCV completed: {len(classified_peaks)} peaks detected\")\n",
    "        \n",
    "        return {\n",
    "            'peaks': classified_peaks,\n",
    "            'algorithm': 'HybridCV (Derivative-Based)',\n",
    "            'derivatives': {\n",
    "                'first': derivatives['first_derivative'].tolist(),\n",
    "                'second': derivatives['second_derivative'].tolist(),\n",
    "                'slope': derivatives['slope'].tolist()\n",
    "            },\n",
    "            'smoothed_current': current_smooth.tolist(),\n",
    "            'zero_crossings': zero_crossings.tolist(),\n",
    "            'parameters': {\n",
    "                'smoothing_window': self.smoothing_window,\n",
    "                'noise_factor': self.noise_factor,\n",
    "                'prominence_factor': self.prominence_factor\n",
    "            },\n",
    "            'total_peaks': len(classified_peaks)\n",
    "        }\n",
    "    \n",
    "    def _smooth_data(self, current: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Apply adaptive Savitzky-Golay smoothing\n",
    "        \"\"\"\n",
    "        # Calculate adaptive window size\n",
    "        if self.smoothing_window is None:\n",
    "            window_length = min(11, len(current) // 10)\n",
    "        else:\n",
    "            window_length = self.smoothing_window\n",
    "            \n",
    "        # Ensure odd window size\n",
    "        if window_length % 2 == 0:\n",
    "            window_length += 1\n",
    "            \n",
    "        # Apply smoothing if window is large enough\n",
    "        if window_length >= 3 and len(current) >= window_length:\n",
    "            current_smooth = savgol_filter(current, window_length, 3)\n",
    "            print(f\"   ‚úÖ Applied Savitzky-Golay filter (window={window_length})\")\n",
    "        else:\n",
    "            current_smooth = current.copy()\n",
    "            print(f\"   ‚ö†Ô∏è Skipped smoothing (insufficient data, window={window_length})\")\n",
    "            \n",
    "        return current_smooth\n",
    "    \n",
    "    def _calculate_derivatives(self, voltage: np.ndarray, current_smooth: np.ndarray) -> Dict:\n",
    "        \"\"\"\n",
    "        Calculate first and second derivatives\n",
    "        \"\"\"\n",
    "        # Calculate gradients\n",
    "        dv = np.gradient(voltage)\n",
    "        di = np.gradient(current_smooth)\n",
    "        \n",
    "        # First derivative (slope)\n",
    "        slope = di / dv\n",
    "        \n",
    "        # Second derivative (curvature)\n",
    "        d2i = np.gradient(slope)\n",
    "        \n",
    "        print(f\"   üìê First derivative range: {slope.min():.3f} to {slope.max():.3f}\")\n",
    "        print(f\"   üìê Second derivative range: {d2i.min():.3f} to {d2i.max():.3f}\")\n",
    "        \n",
    "        return {\n",
    "            'first_derivative': di,\n",
    "            'slope': slope,\n",
    "            'second_derivative': d2i\n",
    "        }\n",
    "    \n",
    "    def _detect_zero_crossings(self, second_derivative: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Detect zero crossings in second derivative\n",
    "        \"\"\"\n",
    "        # Find sign changes (zero crossings)\n",
    "        zero_crossings = np.where(np.diff(np.signbit(second_derivative)))[0]\n",
    "        \n",
    "        print(f\"   üéØ Found {len(zero_crossings)} zero crossings\")\n",
    "        \n",
    "        return zero_crossings\n",
    "    \n",
    "    def _validate_and_filter_peaks(self, zero_crossings: np.ndarray, voltage: np.ndarray, \n",
    "                                 current: np.ndarray, current_smooth: np.ndarray, \n",
    "                                 derivatives: Dict) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Validate and filter potential peaks\n",
    "        \"\"\"\n",
    "        # Calculate adaptive thresholds\n",
    "        current_std = np.std(current)\n",
    "        current_range = np.max(current) - np.min(current)\n",
    "        \n",
    "        min_peak_height = max(current_std * self.noise_factor, current_range * 0.01)\n",
    "        min_prominence = max(current_std * self.prominence_factor, current_range * 0.005)\n",
    "        \n",
    "        print(f\"   üìä Adaptive thresholds:\")\n",
    "        print(f\"      Min height: {min_peak_height:.3f} ¬µA\")\n",
    "        print(f\"      Min prominence: {min_prominence:.3f} ¬µA\")\n",
    "        \n",
    "        peaks = []\n",
    "        \n",
    "        for idx in zero_crossings:\n",
    "            # Skip edge points\n",
    "            if idx < 5 or idx >= len(current) - 5:\n",
    "                continue\n",
    "                \n",
    "            # Get peak properties\n",
    "            peak_current = current[idx]\n",
    "            peak_voltage = voltage[idx]\n",
    "            \n",
    "            # Calculate local baseline\n",
    "            baseline_window = slice(max(0, idx-10), min(len(current), idx+10))\n",
    "            local_baseline = np.mean(current[baseline_window])\n",
    "            peak_height = abs(peak_current - local_baseline)\n",
    "            \n",
    "            # Height filtering\n",
    "            if peak_height < min_peak_height:\n",
    "                continue\n",
    "                \n",
    "            # Prominence calculation\n",
    "            left_window = slice(max(0, idx-5), idx)\n",
    "            right_window = slice(idx+1, min(len(current), idx+6))\n",
    "            \n",
    "            left_vals = current[left_window] if left_window.start < left_window.stop else [peak_current]\n",
    "            right_vals = current[right_window] if right_window.start < right_window.stop else [peak_current]\n",
    "            \n",
    "            left_min = np.min(left_vals) if len(left_vals) > 0 else peak_current\n",
    "            right_min = np.min(right_vals) if len(right_vals) > 0 else peak_current\n",
    "            prominence = abs(peak_current) - max(abs(left_min), abs(right_min))\n",
    "            \n",
    "            # Prominence filtering\n",
    "            if prominence < min_prominence:\n",
    "                continue\n",
    "                \n",
    "            # Determine peak type based on current value\n",
    "            peak_type = 'oxidation' if peak_current > local_baseline else 'reduction'\n",
    "            \n",
    "            # Calculate confidence based on multiple factors\n",
    "            height_score = min(100.0, (peak_height / max(current_range, 1e-10)) * 100)\n",
    "            prominence_score = min(100.0, (prominence / max(current_range, 1e-10)) * 100)\n",
    "            curvature_score = min(100.0, abs(derivatives['second_derivative'][idx]) * 10)\n",
    "            \n",
    "            confidence = (height_score * 0.4 + prominence_score * 0.4 + curvature_score * 0.2)\n",
    "            \n",
    "            # Calculate peak width (approximate)\n",
    "            peak_width = self._calculate_peak_width(idx, current, voltage)\n",
    "            \n",
    "            peak_data = {\n",
    "                'index': int(idx),\n",
    "                'voltage': float(peak_voltage),\n",
    "                'current': float(peak_current),\n",
    "                'type': peak_type,\n",
    "                'confidence': float(confidence),\n",
    "                'height': float(peak_height),\n",
    "                'prominence': float(prominence),\n",
    "                'width_voltage': float(peak_width),\n",
    "                'baseline_current': float(local_baseline),\n",
    "                'curvature': float(derivatives['second_derivative'][idx]),\n",
    "                'slope': float(derivatives['slope'][idx])\n",
    "            }\n",
    "            \n",
    "            peaks.append(peak_data)\n",
    "        \n",
    "        # Sort by confidence and limit number\n",
    "        peaks.sort(key=lambda x: x['confidence'], reverse=True)\n",
    "        if len(peaks) > 20:  # Reasonable limit\n",
    "            peaks = peaks[:20]\n",
    "            \n",
    "        print(f\"   ‚úÖ Validated {len(peaks)} peaks from {len(zero_crossings)} candidates\")\n",
    "        \n",
    "        return peaks\n",
    "    \n",
    "    def _calculate_peak_width(self, idx: int, current: np.ndarray, voltage: np.ndarray) -> float:\n",
    "        \"\"\"\n",
    "        Calculate approximate peak width at half maximum\n",
    "        \"\"\"\n",
    "        peak_current = current[idx]\n",
    "        half_height = peak_current / 2\n",
    "        \n",
    "        # Find left boundary\n",
    "        left_idx = idx\n",
    "        while left_idx > 0 and abs(current[left_idx]) > abs(half_height):\n",
    "            left_idx -= 1\n",
    "            \n",
    "        # Find right boundary\n",
    "        right_idx = idx\n",
    "        while right_idx < len(current) - 1 and abs(current[right_idx]) > abs(half_height):\n",
    "            right_idx += 1\n",
    "            \n",
    "        peak_width = voltage[right_idx] - voltage[left_idx]\n",
    "        return abs(peak_width)\n",
    "    \n",
    "    def _fallback_detection(self, voltage: np.ndarray, current: np.ndarray) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Fallback peak detection using scipy find_peaks\n",
    "        \"\"\"\n",
    "        print(\"   üîÑ Using fallback prominence-based detection\")\n",
    "        \n",
    "        # Normalize current\n",
    "        current_max = np.abs(current).max()\n",
    "        if current_max == 0:\n",
    "            return []\n",
    "            \n",
    "        current_norm = current / current_max\n",
    "        \n",
    "        peaks = []\n",
    "        \n",
    "        # Find positive peaks\n",
    "        pos_peaks, _ = find_peaks(current_norm, prominence=0.1, width=3)\n",
    "        for peak_idx in pos_peaks:\n",
    "            peaks.append({\n",
    "                'index': int(peak_idx),\n",
    "                'voltage': float(voltage[peak_idx]),\n",
    "                'current': float(current[peak_idx]),\n",
    "                'type': 'oxidation',\n",
    "                'confidence': 75.0,\n",
    "                'height': abs(float(current[peak_idx])),\n",
    "                'prominence': abs(float(current[peak_idx])) * 0.1,\n",
    "                'width_voltage': 0.05,  # Default width\n",
    "                'baseline_current': 0.0,\n",
    "                'curvature': 0.0,\n",
    "                'slope': 0.0\n",
    "            })\n",
    "            \n",
    "        # Find negative peaks\n",
    "        neg_peaks, _ = find_peaks(-current_norm, prominence=0.1, width=3)\n",
    "        for peak_idx in neg_peaks:\n",
    "            peaks.append({\n",
    "                'index': int(peak_idx),\n",
    "                'voltage': float(voltage[peak_idx]),\n",
    "                'current': float(current[peak_idx]),\n",
    "                'type': 'reduction',\n",
    "                'confidence': 75.0,\n",
    "                'height': abs(float(current[peak_idx])),\n",
    "                'prominence': abs(float(current[peak_idx])) * 0.1,\n",
    "                'width_voltage': 0.05,  # Default width\n",
    "                'baseline_current': 0.0,\n",
    "                'curvature': 0.0,\n",
    "                'slope': 0.0\n",
    "            })\n",
    "            \n",
    "        print(f\"   ‚úÖ Fallback found {len(peaks)} peaks\")\n",
    "        return peaks\n",
    "    \n",
    "    def _classify_peaks(self, peaks: List[Dict]) -> List[Dict]:\n",
    "        \"\"\"\n",
    "        Final peak classification and cleanup\n",
    "        \"\"\"\n",
    "        classified_peaks = []\n",
    "        \n",
    "        for peak in peaks:\n",
    "            # Clean up peak data for output\n",
    "            classified_peak = {\n",
    "                'voltage': peak['voltage'],\n",
    "                'current': peak['current'],\n",
    "                'type': peak['type'],\n",
    "                'confidence': peak['confidence'],\n",
    "                'height': peak['height'],\n",
    "                'prominence': peak['prominence'],\n",
    "                'width_voltage': peak['width_voltage'],\n",
    "                'baseline_current': peak['baseline_current'],\n",
    "                'curvature': peak['curvature'],\n",
    "                'slope': peak['slope'],\n",
    "                'enabled': peak['confidence'] > 30.0  # Enable peaks with >30% confidence\n",
    "            }\n",
    "            \n",
    "            classified_peaks.append(classified_peak)\n",
    "        \n",
    "        # Sort peaks by voltage\n",
    "        classified_peaks.sort(key=lambda x: x['voltage'])\n",
    "        \n",
    "        print(f\"   üè∑Ô∏è Classified {len(classified_peaks)} peaks\")\n",
    "        \n",
    "        return classified_peaks\n",
    "\n",
    "print(\"‚úÖ HybridCV Detector class implemented\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c06e7c5",
   "metadata": {},
   "source": [
    "## Practical Example: HybridCV in Action\n",
    "\n",
    "Let's demonstrate the HybridCV algorithm with synthetic CV data and compare its derivative-based approach with the other methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4231825b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_synthetic_cv_data(n_points=1000, noise_level=0.05):\n",
    "    \"\"\"\n",
    "    Generate synthetic CV data with redox peaks\n",
    "    (Same function as used in other analyses for comparison)\n",
    "    \"\"\"\n",
    "    # Voltage sweep: -0.2V to +0.8V and back\n",
    "    v_forward = np.linspace(-0.2, 0.8, n_points//2)\n",
    "    v_reverse = np.linspace(0.8, -0.2, n_points//2)\n",
    "    voltage = np.concatenate([v_forward, v_reverse])\n",
    "    \n",
    "    # Peak parameters\n",
    "    oxidation_peak = 0.32   # Anodic peak\n",
    "    reduction_peak = 0.16   # Cathodic peak\n",
    "    peak_width = 0.08       # Peak width\n",
    "    peak_height = 10.0      # Peak height (¬µA)\n",
    "    \n",
    "    # Generate current response\n",
    "    current = np.zeros_like(voltage)\n",
    "    \n",
    "    # Forward sweep (oxidation peak)\n",
    "    for i, v in enumerate(voltage[:n_points//2]):\n",
    "        if v > 0.1:  # Only positive voltages\n",
    "            current[i] += peak_height * np.exp(-((v - oxidation_peak) / peak_width)**2)\n",
    "    \n",
    "    # Reverse sweep (reduction peak)\n",
    "    for i, v in enumerate(voltage[n_points//2:], start=n_points//2):\n",
    "        if v < 0.4:  # Lower voltage region\n",
    "            current[i] -= peak_height * 0.8 * np.exp(-((v - reduction_peak) / peak_width)**2)\n",
    "    \n",
    "    # Add capacitive current (linear background)\n",
    "    capacitive_current = 0.5 * voltage\n",
    "    current += capacitive_current\n",
    "    \n",
    "    # Add noise\n",
    "    noise = np.random.normal(0, noise_level * peak_height, len(current))\n",
    "    current += noise\n",
    "    \n",
    "    return voltage, current\n",
    "\n",
    "# Generate example data\n",
    "voltage_example, current_example = generate_synthetic_cv_data(n_points=800, noise_level=0.08)\n",
    "\n",
    "print(f\"‚úÖ Generated synthetic CV data for HybridCV analysis:\")\n",
    "print(f\"   üìä {len(voltage_example)} data points\")\n",
    "print(f\"   üìä Voltage range: {voltage_example.min():.2f} to {voltage_example.max():.2f} V\")\n",
    "print(f\"   üìä Current range: {current_example.min():.2f} to {current_example.max():.2f} ¬µA\")\n",
    "\n",
    "# Quick visualization\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(voltage_example, current_example, 'b-', alpha=0.7, linewidth=1.5)\n",
    "plt.xlabel('Voltage (V)')\n",
    "plt.ylabel('Current (¬µA)')\n",
    "plt.title('Synthetic CV Data for HybridCV Analysis')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "print(\"üìà Ready for HybridCV derivative analysis\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3113fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and run HybridCV detector\n",
    "detector = HybridCVDetector(smoothing_window=9, noise_factor=0.2, prominence_factor=0.1)\n",
    "\n",
    "# Run the analysis\n",
    "print(\"üöÄ Running HybridCV Analysis...\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "results = detector.detect_peaks_derivative(voltage_example, current_example)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 60)\n",
    "print(\"üìä HybridCV Results Summary:\")\n",
    "print(f\"   Algorithm: {results['algorithm']}\")\n",
    "print(f\"   Total peaks detected: {results['total_peaks']}\")\n",
    "print(f\"   Zero crossings found: {len(results['zero_crossings'])}\")\n",
    "print(f\"   Parameters used:\")\n",
    "for param, value in results['parameters'].items():\n",
    "    print(f\"     - {param}: {value}\")\n",
    "\n",
    "# Display detailed peak information\n",
    "print(\"\\nüîç Detailed Peak Analysis:\")\n",
    "print(\"-\" * 110)\n",
    "print(f\"{'Type':<12} {'Voltage':<10} {'Current':<10} {'Confidence':<12} {'Curvature':<12} {'Slope':<10} {'Width(V)':<10}\")\n",
    "print(\"-\" * 110)\n",
    "\n",
    "enabled_peaks = [p for p in results['peaks'] if p['enabled']]\n",
    "for peak in enabled_peaks:\n",
    "    print(f\"{peak['type']:<12} {peak['voltage']:<10.3f} {peak['current']:<10.3f} {peak['confidence']:<12.1f} {peak['curvature']:<12.3f} {peak['slope']:<10.3f} {peak['width_voltage']:<10.3f}\")\n",
    "\n",
    "print(\"-\" * 110)\n",
    "print(f\"‚úÖ Found {len(enabled_peaks)} validated peaks using derivative-based detection\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5176f0c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize derivative analysis process\n",
    "plt.figure(figsize=(16, 12))\n",
    "\n",
    "# Extract data for visualization\n",
    "smoothed_current = np.array(results['smoothed_current'])\n",
    "first_derivative = np.array(results['derivatives']['first'])\n",
    "second_derivative = np.array(results['derivatives']['second'])\n",
    "slope = np.array(results['derivatives']['slope'])\n",
    "zero_crossings = np.array(results['zero_crossings'])\n",
    "enabled_peaks = [p for p in results['peaks'] if p['enabled']]\n",
    "\n",
    "# 1. Original vs Smoothed Data\n",
    "plt.subplot(3, 3, 1)\n",
    "plt.plot(voltage_example, current_example, 'b-', alpha=0.6, linewidth=1, label='Original Data')\n",
    "plt.plot(voltage_example, smoothed_current, 'r-', linewidth=2, label='Smoothed Data')\n",
    "plt.xlabel('Voltage (V)')\n",
    "plt.ylabel('Current (¬µA)')\n",
    "plt.title('Data Smoothing (Savitzky-Golay)')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 2. First Derivative\n",
    "plt.subplot(3, 3, 2)\n",
    "plt.plot(voltage_example, first_derivative, 'g-', linewidth=2, label='dI/dt')\n",
    "plt.axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
    "plt.xlabel('Voltage (V)')\n",
    "plt.ylabel('dI/dt (¬µA/s)')\n",
    "plt.title('First Derivative')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 3. Second Derivative with Zero Crossings\n",
    "plt.subplot(3, 3, 3)\n",
    "plt.plot(voltage_example, second_derivative, 'm-', linewidth=2, label='d¬≤I/dV¬≤')\n",
    "plt.axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
    "\n",
    "# Mark zero crossings\n",
    "if len(zero_crossings) > 0:\n",
    "    crossing_voltages = voltage_example[zero_crossings]\n",
    "    crossing_values = second_derivative[zero_crossings]\n",
    "    plt.scatter(crossing_voltages, crossing_values, c='red', s=100, marker='o', \n",
    "               label=f'Zero Crossings ({len(zero_crossings)})', zorder=5)\n",
    "\n",
    "plt.xlabel('Voltage (V)')\n",
    "plt.ylabel('d¬≤I/dV¬≤ (¬µA/V¬≤)')\n",
    "plt.title('Second Derivative & Zero Crossings')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 4. Slope Analysis\n",
    "plt.subplot(3, 3, 4)\n",
    "plt.plot(voltage_example, slope, 'orange', linewidth=2, label='dI/dV')\n",
    "plt.axhline(y=0, color='k', linestyle='--', alpha=0.5)\n",
    "plt.xlabel('Voltage (V)')\n",
    "plt.ylabel('Slope (¬µA/V)')\n",
    "plt.title('Current-Voltage Slope')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 5. Final Peak Detection Results\n",
    "plt.subplot(3, 3, 5)\n",
    "plt.plot(voltage_example, current_example, 'b-', alpha=0.6, linewidth=1.5, label='CV Data')\n",
    "\n",
    "# Plot detected peaks\n",
    "oxidation_peaks = [p for p in enabled_peaks if p['type'] == 'oxidation']\n",
    "reduction_peaks = [p for p in enabled_peaks if p['type'] == 'reduction']\n",
    "\n",
    "if oxidation_peaks:\n",
    "    ox_v = [p['voltage'] for p in oxidation_peaks]\n",
    "    ox_i = [p['current'] for p in oxidation_peaks]\n",
    "    plt.scatter(ox_v, ox_i, c='red', s=150, marker='^', label='Oxidation Peaks', zorder=5, edgecolors='darkred')\n",
    "\n",
    "if reduction_peaks:\n",
    "    red_v = [p['voltage'] for p in reduction_peaks]\n",
    "    red_i = [p['current'] for p in reduction_peaks]\n",
    "    plt.scatter(red_v, red_i, c='green', s=150, marker='v', label='Reduction Peaks', zorder=5, edgecolors='darkgreen')\n",
    "\n",
    "plt.xlabel('Voltage (V)')\n",
    "plt.ylabel('Current (¬µA)')\n",
    "plt.title('HybridCV: Final Peak Detection')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 6. Peak Confidence Analysis\n",
    "plt.subplot(3, 3, 6)\n",
    "if enabled_peaks:\n",
    "    confidences = [p['confidence'] for p in enabled_peaks]\n",
    "    peak_types = [p['type'] for p in enabled_peaks]\n",
    "    colors = ['red' if t == 'oxidation' else 'green' for t in peak_types]\n",
    "    \n",
    "    plt.bar(range(len(confidences)), confidences, color=colors, alpha=0.7, edgecolor='black')\n",
    "    plt.xlabel('Peak Index')\n",
    "    plt.ylabel('Confidence Score (%)')\n",
    "    plt.title('Peak Confidence Scores')\n",
    "    plt.axhline(y=30, color='orange', linestyle='--', linewidth=2, label='Threshold')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 7. Curvature Analysis\n",
    "plt.subplot(3, 3, 7)\n",
    "if enabled_peaks:\n",
    "    curvatures = [abs(p['curvature']) for p in enabled_peaks]\n",
    "    plt.bar(range(len(curvatures)), curvatures, color=colors, alpha=0.7, edgecolor='black')\n",
    "    plt.xlabel('Peak Index')\n",
    "    plt.ylabel('|Curvature|')\n",
    "    plt.title('Peak Curvature (Sharpness)')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 8. Slope at Peak Analysis\n",
    "plt.subplot(3, 3, 8)\n",
    "if enabled_peaks:\n",
    "    peak_slopes = [abs(p['slope']) for p in enabled_peaks]\n",
    "    plt.bar(range(len(peak_slopes)), peak_slopes, color=colors, alpha=0.7, edgecolor='black')\n",
    "    plt.xlabel('Peak Index')\n",
    "    plt.ylabel('|Slope at Peak|')\n",
    "    plt.title('Slope Analysis at Peaks')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "\n",
    "# 9. Algorithm Performance Summary\n",
    "plt.subplot(3, 3, 9)\n",
    "summary_text = f\"\"\"\n",
    "HybridCV Summary:\n",
    "\n",
    "‚Ä¢ Algorithm: Derivative-based\n",
    "‚Ä¢ Zero crossings: {len(zero_crossings)}\n",
    "‚Ä¢ Valid peaks: {len(enabled_peaks)}\n",
    "‚Ä¢ Oxidation: {len(oxidation_peaks)}\n",
    "‚Ä¢ Reduction: {len(reduction_peaks)}\n",
    "\n",
    "‚Ä¢ Avg Confidence: {np.mean([p['confidence'] for p in enabled_peaks]):.1f}%\n",
    "‚Ä¢ Avg Curvature: {np.mean([abs(p['curvature']) for p in enabled_peaks]):.3f}\n",
    "‚Ä¢ Avg Slope: {np.mean([abs(p['slope']) for p in enabled_peaks]):.3f}\n",
    "\n",
    "‚Ä¢ Method: Second derivative\n",
    "‚Ä¢ Smoothing: Savitzky-Golay\n",
    "‚Ä¢ Best for: Mathematical analysis\n",
    "\"\"\"\n",
    "\n",
    "plt.text(0.05, 0.95, summary_text, transform=plt.gca().transAxes, \n",
    "         fontsize=10, verticalalignment='top', \n",
    "         bbox=dict(boxstyle='round', facecolor='lightgreen', alpha=0.8))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"üìà HybridCV derivative analysis visualization complete\")\n",
    "print(f\"üéØ Successfully identified {len(enabled_peaks)} peaks from {len(zero_crossings)} zero crossings\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dccaf86c",
   "metadata": {},
   "source": [
    "## HybridCV Algorithm: Advantages and Limitations\n",
    "\n",
    "### ‚úÖ Advantages\n",
    "\n",
    "1. **Mathematical Rigor**:\n",
    "   - Based on fundamental calculus principles\n",
    "   - Zero-crossing detection is theoretically sound\n",
    "   - Provides quantitative curvature and slope information\n",
    "\n",
    "2. **Noise Robustness**:\n",
    "   - Savitzky-Golay filtering preserves peak shapes\n",
    "   - Derivative analysis can reveal hidden peaks\n",
    "   - Less sensitive to baseline variations\n",
    "\n",
    "3. **Peak Shape Analysis**:\n",
    "   - Provides curvature (sharpness) measurements\n",
    "   - Slope information at peak positions\n",
    "   - Can detect subtle shoulder peaks\n",
    "\n",
    "4. **Adaptive Processing**:\n",
    "   - Automatic window size selection for smoothing\n",
    "   - Adaptive threshold calculation\n",
    "   - Robust fallback mechanisms\n",
    "\n",
    "5. **Physical Insight**:\n",
    "   - Derivative analysis reflects electrochemical kinetics\n",
    "   - Curvature relates to peak reversibility\n",
    "   - Slope indicates reaction rate characteristics\n",
    "\n",
    "### ‚ö†Ô∏è Limitations\n",
    "\n",
    "1. **Sensitivity to Noise**:\n",
    "   - Derivatives amplify high-frequency noise\n",
    "   - Requires good signal-to-noise ratio\n",
    "   - May produce false peaks from noise spikes\n",
    "\n",
    "2. **Parameter Dependency**:\n",
    "   - Smoothing window size affects results\n",
    "   - Threshold selection is critical\n",
    "   - May require optimization for different systems\n",
    "\n",
    "3. **Computational Complexity**:\n",
    "   - More processing than simple prominence methods\n",
    "   - Multiple derivative calculations\n",
    "   - Smoothing operations add overhead\n",
    "\n",
    "4. **Edge Effects**:\n",
    "   - Gradient calculations affect data endpoints\n",
    "   - May miss peaks near voltage limits\n",
    "   - Requires careful boundary handling\n",
    "\n",
    "### üéØ Best Use Cases\n",
    "\n",
    "- **Mathematical Analysis**: When detailed peak shape analysis is needed\n",
    "- **Subtle Peak Detection**: Finding shoulder peaks or weak signals\n",
    "- **Kinetic Studies**: Understanding reaction rate characteristics\n",
    "- **Method Development**: Optimizing electrochemical parameters\n",
    "- **Research Applications**: Detailed electrochemical mechanism studies"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9be0bba",
   "metadata": {},
   "source": [
    "## Comprehensive Algorithm Comparison\n",
    "\n",
    "### üìä Three-Algorithm Performance Matrix\n",
    "\n",
    "| Characteristic | TraditionalCV | HybridCV | DeepCV |\n",
    "|----------------|---------------|----------|--------|\n",
    "| **Core Method** | Prominence-based | Derivative-based | ML-enhanced |\n",
    "| **Mathematical Basis** | Signal processing | Calculus | Feature extraction |\n",
    "| **Processing Speed** | Fastest (~1ms) | Moderate (~3ms) | Slowest (~8ms) |\n",
    "| **Noise Tolerance** | Moderate | Good (with smoothing) | Excellent |\n",
    "| **Peak Characterization** | Basic | Mathematical | Comprehensive |\n",
    "| **Parameter Complexity** | Low (2-3) | Moderate (4-6) | High (10+) |\n",
    "| **Setup Difficulty** | Easy | Moderate | Complex |\n",
    "| **Interpretability** | High | Moderate | Medium |\n",
    "| **Shoulder Peak Detection** | Poor | Excellent | Good |\n",
    "| **Overlapping Peaks** | Poor | Moderate | Good |\n",
    "| **Baseline Sensitivity** | Low | Low | Very Low |\n",
    "| **False Positive Rate** | Moderate | Moderate | Low |\n",
    "| **Educational Value** | High | High | Medium |\n",
    "\n",
    "### üî¨ Research Application Guidelines\n",
    "\n",
    "#### **Choose TraditionalCV for:**\n",
    "- Standard electrochemical analysis\n",
    "- High-throughput screening\n",
    "- Educational demonstrations\n",
    "- Baseline performance comparisons\n",
    "- Real-time monitoring applications\n",
    "\n",
    "#### **Choose HybridCV for:**\n",
    "- Mathematical peak shape analysis\n",
    "- Detection of subtle features\n",
    "- Kinetic parameter extraction\n",
    "- Research requiring physical insight\n",
    "- Complex peak shape studies\n",
    "\n",
    "#### **Choose DeepCV for:**\n",
    "- Noisy or complex datasets\n",
    "- Automated quality assessment\n",
    "- Comprehensive peak characterization\n",
    "- Research requiring confidence metrics\n",
    "- Multi-parameter optimization studies\n",
    "\n",
    "### üìà Performance Benchmarking Strategy\n",
    "\n",
    "For research papers, consider this validation approach:\n",
    "\n",
    "```python\n",
    "validation_metrics = {\n",
    "    'TraditionalCV': {\n",
    "        'strengths': ['Speed', 'Simplicity', 'Reliability'],\n",
    "        'use_cases': ['Routine analysis', 'QC', 'Teaching'],\n",
    "        'performance': 'Baseline reference'\n",
    "    },\n",
    "    'HybridCV': {\n",
    "        'strengths': ['Mathematical rigor', 'Shape analysis', 'Subtle peaks'],\n",
    "        'use_cases': ['Research', 'Method development', 'Kinetics'],\n",
    "        'performance': 'Specialized applications'\n",
    "    },\n",
    "    'DeepCV': {\n",
    "        'strengths': ['Robustness', 'Comprehensive analysis', 'Confidence'],\n",
    "        'use_cases': ['Complex data', 'Automation', 'Quality control'],\n",
    "        'performance': 'Advanced analysis'\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "### üéØ Research Paper Conclusions\n",
    "\n",
    "1. **Algorithm Diversity**: The three algorithms represent complementary approaches, each optimized for different aspects of CV analysis\n",
    "\n",
    "2. **Performance Trade-offs**: Speed vs. accuracy vs. detail - no single algorithm dominates all metrics\n",
    "\n",
    "3. **Application-Specific Selection**: Choice depends on data quality, analysis requirements, and computational constraints\n",
    "\n",
    "4. **Future Directions**: Hybrid approaches combining strengths of each method show promise for next-generation peak detection\n",
    "\n",
    "5. **Validation Framework**: Comprehensive comparison provides robust foundation for method selection and optimization"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
