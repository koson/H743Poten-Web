#!/usr/bin/env python3
"""
Data Splitting Strategy Analysis for Peak Detection Framework
р╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣Мр╣Бр╕ер╕░р╣Бр╕Щр╕░р╕Щр╕│р╕Бр╕▓р╕гр╣Бр╕Ър╣Ир╕Зр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕кр╕│р╕лр╕гр╕▒р╕Ъ validation
"""

import pandas as pd
import numpy as np
from pathlib import Path
import json
from collections import defaultdict
import random

class DataSplittingAnalyzer:
    def __init__(self):
        self.base_path = Path("validation_data")
        self.palmsens_path = self.base_path / "reference_cv_data" / "palmsens"
        self.stm32_path = self.base_path / "reference_cv_data" / "stm32h743"
    
    def analyze_data_distribution(self):
        """р╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣Мр╕Бр╕▓р╕гр╕Бр╕гр╕░р╕Ир╕▓р╕вр╕Вр╕нр╕Зр╕Вр╣Йр╕нр╕бр╕╣р╕ер╣Ар╕Юр╕╖р╣Ир╕нр╕зр╕▓р╕Зр╣Бр╕Ьр╕Щр╕Бр╕▓р╕гр╣Бр╕Ър╣Ир╕З"""
        
        print("ЁЯУК р╕Бр╕▓р╕гр╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣Мр╕Бр╕▓р╕гр╕Бр╕гр╕░р╕Ир╕▓р╕вр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕кр╕│р╕лр╕гр╕▒р╕Ъ Peak Detection")
        print("=" * 70)
        
        # р╕Щр╕▒р╕Ър╣Др╕Яр╕ер╣Мр╣Бр╕ер╕░р╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣М patterns
        palmsens_files = list(self.palmsens_path.glob("*.csv")) if self.palmsens_path.exists() else []
        stm32_files = list(self.stm32_path.glob("*.csv")) if self.stm32_path.exists() else []
        
        print(f"ЁЯУБ р╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Чр╕▒р╣Йр╕Зр╕лр╕бр╕Ф:")
        print(f"   PalmSens: {len(palmsens_files)} р╣Др╕Яр╕ер╣М")
        print(f"   STM32H743: {len(stm32_files)} р╣Др╕Яр╕ер╣М")
        print(f"   р╕гр╕зр╕б: {len(palmsens_files) + len(stm32_files)} р╣Др╕Яр╕ер╣М")
        
        # р╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣М experimental conditions
        palmsens_conditions = self._extract_experimental_conditions(palmsens_files, "palmsens")
        stm32_conditions = self._extract_experimental_conditions(stm32_files, "stm32")
        
        print(f"\nЁЯзк р╣Ар╕Зр╕╖р╣Ир╕нр╕Щр╣Др╕Вр╕Бр╕▓р╕гр╕Чр╕Фр╕ер╕нр╕З:")
        print(f"   PalmSens:")
        self._print_conditions(palmsens_conditions)
        print(f"   STM32H743:")
        self._print_conditions(stm32_conditions)
        
        # р╕Др╕│р╕Щр╕зр╕Ур╕Вр╕Щр╕▓р╕Фр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Чр╕╡р╣Ир╣Ар╕лр╕бр╕▓р╕░р╕кр╕б
        self._recommend_splitting_strategy(palmsens_files, stm32_files, palmsens_conditions, stm32_conditions)
        
        return palmsens_conditions, stm32_conditions
    
    def _extract_experimental_conditions(self, files, instrument):
        """р╕кр╕Бр╕▒р╕Фр╣Ар╕Зр╕╖р╣Ир╕нр╕Щр╣Др╕Вр╕Бр╕▓р╕гр╕Чр╕Фр╕ер╕нр╕Зр╕Ир╕▓р╕Бр╕Кр╕╖р╣Ир╕нр╣Др╕Яр╕ер╣М"""
        conditions = defaultdict(set)
        
        for file_path in files:
            try:
                name = file_path.name
                if instrument == "palmsens":
                    # Palmsens_0.5mM_CV_100mVpS_E1_scan_01.csv
                    parts = name.replace('.csv', '').split('_')
                    if len(parts) >= 6:
                        concentration = parts[1]
                        scan_rate = parts[3]
                        electrode = parts[4]
                        scan_num = parts[6]
                        
                        conditions['concentrations'].add(concentration)
                        conditions['scan_rates'].add(scan_rate)
                        conditions['electrodes'].add(electrode)
                        conditions['scan_numbers'].add(scan_num)
                        
                elif instrument == "stm32":
                    # Pipot_Ferro_0_5mM_100mVpS_E1_scan_01.csv р╕лр╕гр╕╖р╕н Pipot_Ferro-10mM_100mVpS_E1_scan_01.csv
                    parts = name.replace('.csv', '').split('_')
                    if len(parts) >= 6:
                        # Handle different naming patterns
                        if 'Ferro-' in parts[1]:
                            # Pipot_Ferro-10mM_100mVpS_E1_scan_01.csv
                            concentration = parts[1].replace('Ferro-', '')
                        else:
                            # Pipot_Ferro_0_5mM_100mVpS_E1_scan_01.csv
                            concentration = f"{parts[2]}.{parts[3]}"
                        
                        scan_rate = parts[-4] if len(parts) > 6 else parts[3]
                        electrode = parts[-3] if len(parts) > 6 else parts[4]
                        scan_num = parts[-1] if len(parts) > 6 else parts[6]
                        
                        conditions['concentrations'].add(concentration)
                        conditions['scan_rates'].add(scan_rate)
                        conditions['electrodes'].add(electrode)
                        conditions['scan_numbers'].add(scan_num)
                        
            except Exception as e:
                continue
        
        # Convert sets to sorted lists
        for key in conditions:
            conditions[key] = sorted(list(conditions[key]))
            
        return dict(conditions)
    
    def _print_conditions(self, conditions):
        """р╕Юр╕┤р╕бр╕Юр╣Мр╣Ар╕Зр╕╖р╣Ир╕нр╕Щр╣Др╕Вр╕Бр╕▓р╕гр╕Чр╕Фр╕ер╕нр╕З"""
        for key, values in conditions.items():
            print(f"     {key}: {values[:10]}{'...' if len(values) > 10 else ''} (р╕гр╕зр╕б {len(values)})")
    
    def _recommend_splitting_strategy(self, palmsens_files, stm32_files, palmsens_conditions, stm32_conditions):
        """р╣Бр╕Щр╕░р╕Щр╕│р╕Бр╕ер╕вр╕╕р╕Чр╕Шр╣Мр╕Бр╕▓р╕гр╣Бр╕Ър╣Ир╕Зр╕Вр╣Йр╕нр╕бр╕╣р╕е"""
        
        print(f"\nЁЯОп р╕Др╕│р╣Бр╕Щр╕░р╕Щр╕│р╕Бр╕▓р╕гр╣Бр╕Ър╣Ир╕Зр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕кр╕│р╕лр╕гр╕▒р╕Ъ Peak Detection Framework:")
        print("=" * 70)
        
        total_files = len(palmsens_files) + len(stm32_files)
        
        # р╕Др╕│р╕Щр╕зр╕Ур╕Бр╕▓р╕гр╣Бр╕Ър╣Ир╕Зр╕Вр╣Йр╕нр╕бр╕╣р╕ер╣Бр╕Щр╕░р╕Щр╕│
        print(f"ЁЯУК р╕Вр╣Йр╕нр╕бр╕╣р╕ер╕Чр╕▒р╣Йр╕Зр╕лр╕бр╕Ф: {total_files:,} р╣Др╕Яр╕ер╣М")
        
        # р╣Бр╕Щр╕░р╕Щр╕│р╕Бр╕▓р╕гр╣Бр╕Ър╣Ир╕Зр╕Хр╕▓р╕бр╕лр╕ер╕▒р╕Бр╕Бр╕▓р╕г ML
        train_percent = 70
        val_percent = 15  
        test_percent = 15
        
        train_size = int(total_files * train_percent / 100)
        val_size = int(total_files * val_percent / 100)
        test_size = total_files - train_size - val_size
        
        print(f"\nЁЯФД р╕Бр╕▓р╕гр╣Бр╕Ър╣Ир╕Зр╕Вр╣Йр╕нр╕бр╕╣р╕ер╣Бр╕Щр╕░р╕Щр╕│:")
        print(f"   ЁЯУЪ Training Set: {train_percent}% = {train_size:,} р╣Др╕Яр╕ер╣М")
        print(f"   ЁЯФН Validation Set: {val_percent}% = {val_size:,} р╣Др╕Яр╕ер╣М") 
        print(f"   ЁЯзк Test Set: {test_percent}% = {test_size:,} р╣Др╕Яр╕ер╣М")
        
        print(f"\nЁЯТб р╣Ар╕лр╕Хр╕╕р╕Ьр╕ер╕Бр╕▓р╕гр╣Бр╕Ър╣Ир╕Зр╣Бр╕Ър╕Ър╕Щр╕╡р╣Й:")
        print(f"   тЬЕ Training (70%): р╕Вр╣Йр╕нр╕бр╕╣р╕ер╣Ар╕Юр╕╡р╕вр╕Зр╕Юр╕нр╕кр╕│р╕лр╕гр╕▒р╕Ър╕Бр╕▓р╕гр╣Ар╕гр╕╡р╕вр╕Щр╕гр╕╣р╣Й pattern")
        print(f"   тЬЕ Validation (15%): р╕кр╕│р╕лр╕гр╕▒р╕Ъ hyperparameter tuning р╣Бр╕ер╕░ model selection")
        print(f"   тЬЕ Test (15%): р╕кр╕│р╕лр╕гр╕▒р╕Ър╕Ыр╕гр╕░р╣Ар╕бр╕┤р╕Щр╕Ыр╕гр╕░р╕кр╕┤р╕Чр╕Шр╕┤р╕ар╕▓р╕Юр╕Ир╕гр╕┤р╕Зр╣Бр╕Ър╕Ъ unbiased")
        
        # р╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣Мр╕Др╕зр╕▓р╕бр╣Ар╕Юр╕╡р╕вр╕Зр╕Юр╕нр╕Вр╕нр╕Зр╕Вр╣Йр╕нр╕бр╕╣р╕е
        print(f"\nЁЯУИ р╕Бр╕▓р╕гр╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣Мр╕Др╕зр╕▓р╕бр╣Ар╕Юр╕╡р╕вр╕Зр╕Юр╕нр╕Вр╕нр╕Зр╕Вр╣Йр╕нр╕бр╕╣р╕е:")
        
        # р╕Др╕│р╕Щр╕зр╕У samples р╕Хр╣Ир╕н condition
        palmsens_combinations = (
            len(palmsens_conditions.get('concentrations', [])) *
            len(palmsens_conditions.get('scan_rates', [])) *
            len(palmsens_conditions.get('electrodes', []))
        )
        
        stm32_combinations = (
            len(stm32_conditions.get('concentrations', [])) *
            len(stm32_conditions.get('scan_rates', [])) *
            len(stm32_conditions.get('electrodes', []))
        )
        
        palmsens_samples_per_condition = len(palmsens_files) / max(palmsens_combinations, 1)
        stm32_samples_per_condition = len(stm32_files) / max(stm32_combinations, 1)
        
        print(f"   PalmSens: ~{palmsens_samples_per_condition:.1f} samples/condition")
        print(f"   STM32H743: ~{stm32_samples_per_condition:.1f} samples/condition")
        
        # р╕Ыр╕гр╕░р╣Ар╕бр╕┤р╕Щр╕Др╕зр╕▓р╕бр╣Ар╕Юр╕╡р╕вр╕Зр╕Юр╕н
        if palmsens_samples_per_condition >= 10 and stm32_samples_per_condition >= 10:
            print(f"   тЬЕ р╕Вр╣Йр╕нр╕бр╕╣р╕ер╣Ар╕Юр╕╡р╕вр╕Зр╕Юр╕нр╕кр╕│р╕лр╕гр╕▒р╕Ър╕Бр╕▓р╕гр╕Эр╕╢р╕Б ML models")
        else:
            print(f"   тЪая╕П  р╕Вр╣Йр╕нр╕бр╕╣р╕ер╕нр╕▓р╕Ир╣Др╕бр╣Ир╣Ар╕Юр╕╡р╕вр╕Зр╕Юр╕нр╕кр╕│р╕лр╕гр╕▒р╕Ър╕Ър╕▓р╕Зр╣Ар╕Зр╕╖р╣Ир╕нр╕Щр╣Др╕В")
        
        # р╣Бр╕Щр╕░р╕Щр╕│р╕Бр╕ер╕вр╕╕р╕Чр╕Шр╣Мр╕Бр╕▓р╕гр╣Бр╕Ър╣Ир╕Зр╣Бр╕Ър╕Ъ stratified
        print(f"\nЁЯО▓ р╕Бр╕ер╕вр╕╕р╕Чр╕Шр╣Мр╕Бр╕▓р╕гр╣Бр╕Ър╣Ир╕Зр╕Вр╣Йр╕нр╕бр╕╣р╕ер╣Бр╕Щр╕░р╕Щр╕│:")
        print(f"   1. ЁЯУК Stratified Splitting: р╣Бр╕Ър╣Ир╕Зр╕Хр╕▓р╕б experimental conditions")
        print(f"   2. ЁЯФД Cross-Instrument Validation: р╣Гр╕Кр╣Й PalmSens р╕Эр╕╢р╕Б, STM32 р╕Чр╕Фр╕кр╕нр╕Ъ (р╣Бр╕ер╕░р╕Чр╕▓р╕Зр╕Бр╕ер╕▒р╕Ъ)")
        print(f"   3. ЁЯзк Cross-Validation: K-fold CV р╕кр╕│р╕лр╕гр╕▒р╕Ър╣Бр╕Хр╣Ир╕ер╕░ instrument")
        print(f"   4. ЁЯМЯ Leave-One-Condition-Out: р╕Чр╕Фр╕кр╕нр╕Ър╕Бр╕▒р╕Ър╣Ар╕Зр╕╖р╣Ир╕нр╕Щр╣Др╕Вр╕Чр╕╡р╣Ир╣Др╕бр╣Ир╣Ар╕Др╕вр╣Ар╕лр╣Зр╕Щ")
        
        # р╣Бр╕Щр╕░р╕Щр╕│р╕Бр╕▓р╕гр╣Гр╕Кр╣Йр╕Зр╕▓р╕Щр╕кр╕│р╕лр╕гр╕▒р╕Ъ 3-method comparison
        print(f"\nЁЯПЖ р╕кр╕│р╕лр╕гр╕▒р╕Ъ 3-Method Peak Detection Comparison:")
        print(f"   ЁЯФ╣ Baseline Detection: р╣Гр╕Кр╣Йр╕Чр╕╕р╕Б data (statistical method)")
        print(f"   ЁЯФ╣ Statistical Peak Detection: р╣Гр╕Кр╣Й training data р╕кр╕│р╕лр╕гр╕▒р╕Ъ parameter tuning")
        print(f"   ЁЯФ╣ ML Peak Detection: р╣Гр╕Кр╣Й training/validation/test split р╣Бр╕Ър╕Ър╣Ар╕Хр╣Зр╕б")
        
        # р╣Бр╕Щр╕░р╕Щр╕│р╕Вр╕Щр╕▓р╕Фр╕Вр╣Йр╕нр╕бр╕╣р╕ер╕кр╕│р╕лр╕гр╕▒р╕Ъ peak detection
        print(f"\nЁЯУП р╕Др╕зр╕▓р╕бр╣Ар╕Юр╕╡р╕вр╕Зр╕Юр╕нр╕кр╕│р╕лр╕гр╕▒р╕Ъ Peak Detection:")
        if total_files > 1000:
            print(f"   тЬЕ EXCELLENT: {total_files:,} р╣Др╕Яр╕ер╣М р╣Ар╕Юр╕╡р╕вр╕Зр╕Юр╕нр╕бр╕▓р╕Бр╕кр╕│р╕лр╕гр╕▒р╕Ъ robust validation")
        elif total_files > 500:
            print(f"   тЬЕ GOOD: {total_files:,} р╣Др╕Яр╕ер╣М р╣Ар╕Юр╕╡р╕вр╕Зр╕Юр╕нр╕кр╕│р╕лр╕гр╕▒р╕Ър╕Бр╕▓р╕гр╕зр╕┤р╣Ар╕Др╕гр╕▓р╕░р╕лр╣Мр╕Чр╕╡р╣Ир╕Фр╕╡")
        elif total_files > 100:
            print(f"   тЪая╕П  MODERATE: {total_files:,} р╣Др╕Яр╕ер╣М р╕Хр╣Йр╕нр╕Зр╕гр╕░р╕зр╕▒р╕Зр╕Бр╕▓р╕г overfitting")
        else:
            print(f"   тЭМ INSUFFICIENT: {total_files:,} р╣Др╕Яр╕ер╣М р╕Щр╣Йр╕нр╕вр╣Ар╕Бр╕┤р╕Щр╣Др╕Ыр╕кр╕│р╕лр╕гр╕▒р╕Ъ ML")
            
        print(f"\nЁЯТл р╕Вр╣Йр╕нр╣Ар╕кр╕Щр╕нр╣Бр╕Щр╕░р╣Ар╕Юр╕┤р╣Ир╕бр╣Ар╕Хр╕┤р╕б:")
        print(f"   тАв р╣Гр╕Кр╣Й data augmentation р╕Цр╣Йр╕▓р╕Ир╕│р╣Ар╕Ыр╣Зр╕Щ (noise injection, baseline shifting)")
        print(f"   тАв р╣Ар╕Бр╣Зр╕Ър╕Вр╣Йр╕нр╕бр╕╣р╕е edge cases р╣Др╕зр╣Йр╣Гр╕Щ test set")
        print(f"   тАв р╕гр╕▒р╕Бр╕йр╕▓р╕Др╕зр╕▓р╕бр╕кр╕бр╕Фр╕╕р╕ер╕гр╕░р╕лр╕зр╣Ир╕▓р╕З instruments р╣Гр╕Щ train/val/test")
        print(f"   тАв р╕Юр╕┤р╕Ир╕▓р╕гр╕Ур╕▓ time-based splitting р╕Цр╣Йр╕▓р╕бр╕╡р╕Вр╣Йр╕нр╕бр╕╣р╕е temporal")

def main():
    analyzer = DataSplittingAnalyzer()
    analyzer.analyze_data_distribution()

if __name__ == "__main__":
    main()
