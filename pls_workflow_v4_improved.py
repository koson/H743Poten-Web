#!/usr/bin/env python3
"""
PLS Workflow with Enhanced Detector V4 Improved
===============================================
‡πÉ‡∏ä‡πâ Enhanced Detector V4 Improved ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ detect peak ‡πÅ‡∏•‡∏∞ baseline ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏±‡∏ö‡∏õ‡∏£‡∏∏‡∏á
reduction peak detection ‡πÅ‡∏•‡∏∞ edge effect elimination
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import re
import json
import logging
from datetime import datetime
from sklearn.cross_decomposition import PLSRegression
from sklearn.model_selection import cross_val_score, KFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error

# Import Enhanced Detector V4 Improved
try:
    from enhanced_detector_v4_improved import EnhancedDetectorV4Improved
    ENHANCED_V4_IMPROVED_AVAILABLE = True
    print("‚úÖ Enhanced Detector V4 Improved ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
except ImportError:
    ENHANCED_V4_IMPROVED_AVAILABLE = False
    print("‚ùå Enhanced Detector V4 Improved ‡πÑ‡∏°‡πà‡∏û‡∏ö")
    exit(1)

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

class PLSWorkflowV4Improved:
    """
    PLS Workflow ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ Enhanced Detector V4 Improved
    """
    
    def __init__(self, palmsens_dir="Test_data/Palmsens", stm32_dir="Test_data/Stm32", output_dir="pls_results_v4_improved"):
        self.palmsens_dir = Path(palmsens_dir)
        self.stm32_dir = Path(stm32_dir)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # Initialize Enhanced Detector V4 Improved with lower threshold
        self.detector = EnhancedDetectorV4Improved(confidence_threshold=25.0)
        
        self.results = {
            'data_matrix': [],
            'concentrations': [],
            'scan_rates': [],
            'peak_data': {},
            'missing_combinations': [],
            'detection_stats': {
                'total_files': 0,
                'successful_detections': 0,
                'failed_detections': 0,
                'high_confidence_detections': 0,
                'medium_confidence_detections': 0,
                'low_confidence_detections': 0
            }
        }
    
    def extract_metadata_from_filename(self, filename):
        """‡πÅ‡∏¢‡∏Å concentration ‡πÅ‡∏•‡∏∞ scan rate ‡∏à‡∏≤‡∏Å filename"""
        filename_lower = filename.lower()
        
        # Pattern ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö concentration
        concentration = None
        
        # Palmsens format: Palmsens_0.5mM_...
        conc_match = re.search(r'palmsens[_\s]*(\d+\.?\d*)\s*mm', filename_lower)
        if conc_match:
            concentration = float(conc_match.group(1))
        
        # STM32 format: Pipot_Ferro_0_5mM_... ‡∏´‡∏£‡∏∑‡∏≠ Pipot_Ferro_1_0mM_...
        if concentration is None:
            conc_match = re.search(r'pipot[_\s]*ferro[_\s]*(\d+)[_\s]*(\d+)[_\s]*mm', filename_lower)
            if conc_match:
                major = int(conc_match.group(1))
                minor = int(conc_match.group(2))
                concentration = major + minor / 10.0
        
        # Pattern ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö scan rate
        scan_rate = None
        scan_match = re.search(r'(\d+\.?\d*)\s*mv[\/\s]*p?s', filename_lower)
        if scan_match:
            scan_rate = float(scan_match.group(1))
        
        return concentration, scan_rate
    
    def load_cv_file(self, filepath, device_type):
        """‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå CV ‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏î‡πâ‡∏ß‡∏¢ Enhanced Detector V4 Improved"""
        try:
            self.results['detection_stats']['total_files'] += 1
            
            # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• - skip 2 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÅ‡∏£‡∏Å (‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå + header)
            if device_type == 'palmsens':
                data = pd.read_csv(filepath, skiprows=2, names=['voltage', 'current'])
            else:
                data = pd.read_csv(filepath, skiprows=2, names=['voltage', 'current'])
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            if len(data) == 0:
                logger.warning(f"   ‚ùå ‡πÑ‡∏ü‡∏•‡πå‡∏ß‡πà‡∏≤‡∏á: {filepath.name}")
                self.results['detection_stats']['failed_detections'] += 1
                return None
            
            voltage = data['voltage'].values
            current = data['current'].values
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
            if not (np.isfinite(voltage).all() and np.isfinite(current).all()):
                logger.warning(f"   ‚ùå ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á: {filepath.name}")
                self.results['detection_stats']['failed_detections'] += 1
                return None
            
            # ‡πÉ‡∏ä‡πâ Enhanced Detector V4 Improved ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
            logger.info(f"üî¨ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå {filepath.name} ‡∏î‡πâ‡∏ß‡∏¢ Enhanced Detector V4 Improved...")
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á data structure ‡∏ó‡∏µ‡πà Enhanced V4 Improved ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
            cv_data_dict = {
                'voltage': voltage,
                'current': current
            }
            
            # ‡∏£‡∏±‡∏ô Enhanced Detector V4 Improved
            results = self.detector.analyze_cv_data(cv_data_dict)
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
            if results and 'confidence' in results:
                confidence = results.get('confidence', 0)
                
                # ‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• peaks
                peak_data = results.get('peak_data', {})
                oxidation_peak = peak_data.get('oxidation_peak')
                reduction_peak = peak_data.get('reduction_peak')
                
                # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• baseline
                baseline_data = results.get('baseline_data', {})
                
                # Peak heights ‡πÅ‡∏•‡∏∞ areas
                ox_height = oxidation_peak.get('height') if oxidation_peak else None
                red_height = abs(reduction_peak.get('height')) if reduction_peak else None
                
                ox_area = oxidation_peak.get('area') if oxidation_peak else None
                red_area = abs(reduction_peak.get('area')) if reduction_peak else None
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ peak ‡∏Ñ‡∏£‡∏ö‡∏ó‡∏±‡πâ‡∏á 2 ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                has_both_peaks = (ox_height is not None and red_height is not None and 
                                ox_area is not None and red_area is not None)
                
                # ‡∏à‡∏≥‡πÅ‡∏ô‡∏Å‡∏£‡∏∞‡∏î‡∏±‡∏ö confidence
                if confidence >= 75:
                    self.results['detection_stats']['high_confidence_detections'] += 1
                elif confidence >= 50:
                    self.results['detection_stats']['medium_confidence_detections'] += 1
                else:
                    self.results['detection_stats']['low_confidence_detections'] += 1
                
                if has_both_peaks:
                    self.results['detection_stats']['successful_detections'] += 1
                    status_icon = "‚úÖ"
                else:
                    self.results['detection_stats']['failed_detections'] += 1
                    status_icon = "‚ö†Ô∏è"
                
                logger.info(f"   {status_icon} Confidence: {confidence:.1f}%, Peaks: {'‚úÖ' if has_both_peaks else '‚ùå'}")
                
                return {
                    'voltage': voltage,
                    'current': current,
                    'enhanced_v4_improved_results': results,
                    'confidence': confidence,
                    'anodic_peak': ox_height,
                    'cathodic_peak': red_height,
                    'anodic_area': ox_area,
                    'cathodic_area': red_area,
                    'has_both_peaks': has_both_peaks,
                    'peak_data': peak_data,
                    'baseline_data': baseline_data
                }
            else:
                logger.warning(f"   ‚ùå Enhanced V4 Improved ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏î‡πâ")
                self.results['detection_stats']['failed_detections'] += 1
                return None
                
        except Exception as e:
            logger.error(f"‚ùå Error loading {filepath}: {e}")
            self.results['detection_stats']['failed_detections'] += 1
            return None
    
    def scan_data_files(self, max_files_per_combination=3):
        """‡∏™‡πÅ‡∏Å‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• CV ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏≤‡∏Å Palmsens ‡πÅ‡∏•‡∏∞ STM32"""
        all_files = []
        
        # ‡∏™‡πÅ‡∏Å‡∏ô‡πÑ‡∏ü‡∏•‡πå Palmsens
        if self.palmsens_dir.exists():
            for conc_folder in self.palmsens_dir.iterdir():
                if conc_folder.is_dir():
                    csv_files = list(conc_folder.glob("*.csv"))
                    for f in csv_files:
                        all_files.append((f, 'palmsens'))
        
        # ‡∏™‡πÅ‡∏Å‡∏ô‡πÑ‡∏ü‡∏•‡πå STM32
        if self.stm32_dir.exists():
            for conc_folder in self.stm32_dir.iterdir():
                if conc_folder.is_dir():
                    csv_files = list(conc_folder.glob("*.csv"))
                    for f in csv_files:
                        all_files.append((f, 'stm32'))
        
        print(f"üîç ‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {len(all_files)} ‡πÑ‡∏ü‡∏•‡πå")
        print(f"   - Palmsens: {len([f for f, t in all_files if t == 'palmsens'])} ‡πÑ‡∏ü‡∏•‡πå")
        print(f"   - STM32: {len([f for f, t in all_files if t == 'stm32'])} ‡πÑ‡∏ü‡∏•‡πå")
        
        data_matrix = []
        concentrations = set()
        scan_rates = set()
        combination_counts = {}
        
        for filepath, device_type in all_files:
            # ‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• metadata
            concentration, scan_rate = self.extract_metadata_from_filename(filepath.name)
            
            if concentration is None or scan_rate is None:
                continue
            
            # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πà‡∏≠ combination
            combo_key = (concentration, scan_rate, device_type)
            if combo_key not in combination_counts:
                combination_counts[combo_key] = 0
            
            if combination_counts[combo_key] >= max_files_per_combination:
                continue
            
            combination_counts[combo_key] += 1
            
            # ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏ü‡∏•‡πå
            cv_data = self.load_cv_file(filepath, device_type)
            if cv_data is None:
                continue
            
            # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            row = {
                'filename': filepath.name,
                'filepath': str(filepath),
                'device_type': device_type,
                'concentration': concentration,
                'scan_rate': scan_rate,
                'anodic_peak': cv_data['anodic_peak'],
                'cathodic_peak': cv_data['cathodic_peak'], 
                'anodic_area': cv_data['anodic_area'],
                'cathodic_area': cv_data['cathodic_area'],
                'has_both_peaks': cv_data['has_both_peaks'],
                'confidence': cv_data['confidence'],
                'enhanced_v4_improved_results': cv_data['enhanced_v4_improved_results']
            }
            
            data_matrix.append(row)
            concentrations.add(concentration)
            scan_rates.add(scan_rate)
        
        self.results['data_matrix'] = data_matrix
        self.results['concentrations'] = sorted(concentrations)
        self.results['scan_rates'] = sorted(scan_rates)
        
        return pd.DataFrame(data_matrix)
    
    def print_detection_stats(self):
        """‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£ detect ‡∏Ç‡∏≠‡∏á Enhanced V4 Improved"""
        stats = self.results['detection_stats']
        
        if stats['total_files'] == 0:
            print("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•")
            return
        
        print(f"\nüìä ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£ detect ‡∏î‡πâ‡∏ß‡∏¢ Enhanced Detector V4 Improved:")
        print(f"   üìÅ ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {stats['total_files']}")
        print(f"   ‚úÖ Detect ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {stats['successful_detections']} ({stats['successful_detections']/stats['total_files']*100:.1f}%)")
        print(f"   ‚ùå Detect ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {stats['failed_detections']} ({stats['failed_detections']/stats['total_files']*100:.1f}%)")
        print(f"   üéØ Confidence ‡∏™‡∏π‡∏á (‚â•75%): {stats['high_confidence_detections']} ({stats['high_confidence_detections']/stats['total_files']*100:.1f}%)")
        print(f"   üî∂ Confidence ‡∏Å‡∏•‡∏≤‡∏á (50-75%): {stats['medium_confidence_detections']} ({stats['medium_confidence_detections']/stats['total_files']*100:.1f}%)")
        print(f"   üî∏ Confidence ‡∏ï‡πà‡∏≥ (25-50%): {stats['low_confidence_detections']} ({stats['low_confidence_detections']/stats['total_files']*100:.1f}%)")
    
    def create_data_availability_table(self, df_all):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡∏°‡∏µ"""
        
        availability_table = []
        missing_combinations = []
        
        for device in ['palmsens', 'stm32']:
            device_data = df_all[df_all['device_type'] == device]
            
            for conc in self.results['concentrations']:
                for scan in self.results['scan_rates']:
                    subset = device_data[(device_data['concentration'] == conc) & 
                                       (device_data['scan_rate'] == scan)]
                    valid_peaks = subset[subset['has_both_peaks'] == True]
                    
                    if len(valid_peaks) > 0:
                        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡∏ß‡∏ó‡∏µ‡πà‡∏°‡∏µ confidence ‡∏™‡∏π‡∏á‡∏™‡∏∏‡∏î
                        best_sample = valid_peaks.loc[valid_peaks['confidence'].idxmax()]
                        availability_table.append({
                            'device_type': device,
                            'concentration': conc,
                            'scan_rate': scan, 
                            'available': True,
                            'filename': best_sample['filename'],
                            'confidence': best_sample['confidence'],
                            'anodic_peak': best_sample['anodic_peak'],
                            'cathodic_peak': best_sample['cathodic_peak']
                        })
                    else:
                        missing_combinations.append({
                            'device_type': device,
                            'concentration': conc,
                            'scan_rate': scan,
                            'available': False,
                            'reason': 'No data with both peaks'
                        })
                        availability_table.append({
                            'device_type': device,
                            'concentration': conc,
                            'scan_rate': scan,
                            'available': False, 
                            'filename': None,
                            'confidence': 0,
                            'anodic_peak': None,
                            'cathodic_peak': None
                        })
        
        self.results['missing_combinations'] = missing_combinations
        return pd.DataFrame(availability_table)
    
    def perform_pls_analysis(self, df_availability, device_type='palmsens', min_confidence=25.0):
        """‡∏ó‡∏≥ PLS analysis ‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ"""
        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ peak ‡∏Ñ‡∏£‡∏ö‡πÅ‡∏•‡∏∞ confidence ‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠
        valid_data = df_availability[
            (df_availability['available'] == True) & 
            (df_availability['device_type'] == device_type) &
            (df_availability['confidence'] >= min_confidence)
        ].copy()
        
        if len(valid_data) < 3:
            print(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {device_type} ‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö PLS analysis (‡∏°‡∏µ {len(valid_data)} samples, ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 3)")
            return None
        
        print(f"üß† ‡∏ó‡∏≥ PLS Analysis ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {device_type} ({len(valid_data)} samples, min confidence: {min_confidence}%)...")
        
        # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        X = valid_data[['anodic_peak', 'cathodic_peak']].values
        y = valid_data['concentration'].values
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        if np.any(np.isnan(X)) or np.any(np.isnan(y)):
            print("‚ùå ‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• NaN")
            return None
        
        # Scaling
        scaler_X = StandardScaler()
        scaler_y = StandardScaler()
        
        X_scaled = scaler_X.fit_transform(X)
        y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).ravel()
        
        # PLS Model
        n_components = min(2, X.shape[1], len(y) - 1)
        pls = PLSRegression(n_components=n_components)
        pls.fit(X_scaled, y_scaled)
        
        # Prediction
        y_pred_scaled = pls.predict(X_scaled)
        y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()
        
        # Cross-validation
        cv_folds = min(5, len(y))
        if cv_folds >= 2:
            cv_scores = cross_val_score(pls, X_scaled, y_scaled, cv=cv_folds, scoring='r2')
        else:
            cv_scores = np.array([0])
        
        # Metrics
        r2 = r2_score(y, y_pred)
        rmse = np.sqrt(mean_squared_error(y, y_pred))
        mae = mean_absolute_error(y, y_pred)
        
        results = {
            'device_type': device_type,
            'model': pls,
            'scaler_X': scaler_X,
            'scaler_y': scaler_y,
            'X': X,
            'y': y,
            'y_pred': y_pred,
            'r2': r2,
            'rmse': rmse,
            'mae': mae,
            'cv_scores': cv_scores,
            'cv_mean': cv_scores.mean(),
            'cv_std': cv_scores.std(),
            'n_samples': len(valid_data),
            'n_components': n_components,
            'min_confidence': min_confidence,
            'avg_confidence': valid_data['confidence'].mean()
        }
        
        return results
    
    def run_workflow(self):
        """‡∏£‡∏±‡∏ô workflow ‡∏´‡∏•‡∏±‡∏Å"""
        print("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô PLS Workflow ‡∏î‡πâ‡∏ß‡∏¢ Enhanced Detector V4 Improved")
        print("=" * 65)
        
        # 1. ‡∏™‡πÅ‡∏Å‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        print("\nüìÇ 1. ‡∏™‡πÅ‡∏Å‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• CV...")
        df_all = self.scan_data_files(max_files_per_combination=2)
        print(f"   ‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {len(df_all)} ‡πÑ‡∏ü‡∏•‡πå")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£ detect
        self.print_detection_stats()
        
        # 2. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        print("\nüìä 2. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
        df_availability = self.create_data_availability_table(df_all)
        
        # 3. ‡∏ó‡∏≥ PLS Analysis ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á Palmsens ‡πÅ‡∏•‡∏∞ STM32
        print("\nüß† 3. ‡∏ó‡∏≥ PLS Analysis...")
        
        pls_palmsens = self.perform_pls_analysis(df_availability, 'palmsens', min_confidence=25.0)
        pls_stm32 = self.perform_pls_analysis(df_availability, 'stm32', min_confidence=25.0)
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        if pls_palmsens:
            print(f"\nüìà Palmsens Results ({pls_palmsens['n_samples']} samples, avg confidence: {pls_palmsens['avg_confidence']:.1f}%):")
            print(f"   R¬≤ = {pls_palmsens['r2']:.3f}")
            print(f"   RMSE = {pls_palmsens['rmse']:.3f} mM")
            if pls_palmsens['cv_scores'].size > 1:
                print(f"   CV R¬≤ = {pls_palmsens['cv_mean']:.3f} ¬± {pls_palmsens['cv_std']:.3f}")
        
        if pls_stm32:
            print(f"\nüìà STM32 Results ({pls_stm32['n_samples']} samples, avg confidence: {pls_stm32['avg_confidence']:.1f}%):")
            print(f"   R¬≤ = {pls_stm32['r2']:.3f}")
            print(f"   RMSE = {pls_stm32['rmse']:.3f} mM")
            if pls_stm32['cv_scores'].size > 1:
                print(f"   CV R¬≤ = {pls_stm32['cv_mean']:.3f} ¬± {pls_stm32['cv_std']:.3f}")
        
        # 4. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
        if pls_palmsens or pls_stm32:
            print("\nüìä 4. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•...")
            self.create_visualizations(pls_palmsens, pls_stm32, df_availability)
        
        # 5. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        print("\nüíæ 5. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå...")
        self.save_results(df_availability, pls_palmsens, pls_stm32)
        
        print("\n‚úÖ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô PLS Workflow ‡∏î‡πâ‡∏ß‡∏¢ Enhanced Detector V4 Improved!")
        return pls_palmsens, pls_stm32, df_availability
    
    def create_visualizations(self, pls_palmsens, pls_stm32, df_availability):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•"""
        # Implementation similar to previous version but for V4 Improved
        print("üìä Creating visualization plots...")
        
        # Create simple plot for now
        fig, ax = plt.subplots(1, 1, figsize=(8, 6))
        
        if pls_palmsens:
            y = pls_palmsens['y']
            y_pred = pls_palmsens['y_pred']
            ax.scatter(y, y_pred, alpha=0.7, s=60, color='blue', label='Palmsens')
            
        if pls_stm32:
            y = pls_stm32['y']
            y_pred = pls_stm32['y_pred']
            ax.scatter(y, y_pred, alpha=0.7, s=60, color='red', label='STM32')
        
        # Perfect prediction line
        if pls_palmsens or pls_stm32:
            all_y = []
            all_y_pred = []
            if pls_palmsens:
                all_y.extend(pls_palmsens['y'])
                all_y_pred.extend(pls_palmsens['y_pred'])
            if pls_stm32:
                all_y.extend(pls_stm32['y'])
                all_y_pred.extend(pls_stm32['y_pred'])
            
            min_val = min(min(all_y), min(all_y_pred))
            max_val = max(max(all_y), max(all_y_pred))
            ax.plot([min_val, max_val], [min_val, max_val], 'k--', lw=2, label='Perfect Prediction')
        
        ax.set_xlabel('Actual Concentration (mM)')
        ax.set_ylabel('Predicted Concentration (mM)')
        ax.set_title('PLS Analysis - Enhanced Detector V4 Improved')
        ax.legend()
        ax.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏π‡∏õ
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_path = self.output_dir / f"pls_analysis_v4_improved_{timestamp}.png"
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        print(f"üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà: {output_path}")
        
        plt.show()
    
    def save_results(self, df_availability, pls_palmsens, pls_stm32):
        """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å data availability
        availability_path = self.output_dir / f"data_availability_v4_improved_{timestamp}.csv"
        df_availability.to_csv(availability_path, index=False)
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å summary report
        report_path = self.output_dir / f"pls_report_v4_improved_{timestamp}.txt"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("PLS Analysis Report - Enhanced Detector V4 Improved\n")
            f.write("==================================================\n\n")
            f.write(f"Analysis Date: {datetime.now()}\n")
            f.write(f"Method: Enhanced Detector V4 Improved\n\n")
            
            # Detection stats
            stats = self.results['detection_stats']
            f.write("Detection Statistics:\n")
            f.write(f"- Total files processed: {stats['total_files']}\n")
            f.write(f"- Successful detections: {stats['successful_detections']} ({stats['successful_detections']/stats['total_files']*100:.1f}%)\n")
            f.write(f"- High confidence detections: {stats['high_confidence_detections']} ({stats['high_confidence_detections']/stats['total_files']*100:.1f}%)\n")
            f.write(f"- Medium confidence detections: {stats['medium_confidence_detections']} ({stats['medium_confidence_detections']/stats['total_files']*100:.1f}%)\n")
            f.write(f"- Low confidence detections: {stats['low_confidence_detections']} ({stats['low_confidence_detections']/stats['total_files']*100:.1f}%)\n\n")
            
            if pls_palmsens:
                f.write("Palmsens PLS Results:\n")
                f.write(f"- R¬≤ = {pls_palmsens['r2']:.3f}\n")
                f.write(f"- RMSE = {pls_palmsens['rmse']:.3f} mM\n")
                f.write(f"- Average Confidence = {pls_palmsens['avg_confidence']:.1f}%\n")
                f.write(f"- Samples used = {pls_palmsens['n_samples']}\n\n")
            
            if pls_stm32:
                f.write("STM32 PLS Results:\n")
                f.write(f"- R¬≤ = {pls_stm32['r2']:.3f}\n")
                f.write(f"- RMSE = {pls_stm32['rmse']:.3f} mM\n")
                f.write(f"- Average Confidence = {pls_stm32['avg_confidence']:.1f}%\n")
                f.write(f"- Samples used = {pls_stm32['n_samples']}\n\n")
        
        print(f"   üíæ Data availability: {availability_path}")
        print(f"   üíæ Report: {report_path}")


# ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô
if __name__ == "__main__":
    if not ENHANCED_V4_IMPROVED_AVAILABLE:
        print("‚ùå Enhanced Detector V4 Improved ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
        exit(1)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á workflow
    workflow = PLSWorkflowV4Improved(
        palmsens_dir="Test_data/Palmsens",    # Reference potentiostat
        stm32_dir="Test_data/Stm32",          # Target potentiostat  
        output_dir="pls_results_v4_improved"
    )
    
    # ‡∏£‡∏±‡∏ô workflow
    pls_palmsens, pls_stm32, df_availability = workflow.run_workflow()
    
    # ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    if pls_palmsens or pls_stm32:
        print("\nüéâ PLS Analysis ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
        if pls_palmsens:
            print(f"   Palmsens: R¬≤ = {pls_palmsens['r2']:.3f} (Confidence: {pls_palmsens['avg_confidence']:.1f}%)")
        if pls_stm32:
            print(f"   STM32: R¬≤ = {pls_stm32['r2']:.3f} (Confidence: {pls_stm32['avg_confidence']:.1f}%)")
    else:
        print("\n‚ùå PLS Analysis ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à - ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠")
