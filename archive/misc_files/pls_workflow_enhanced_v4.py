#!/usr/bin/env python3
"""
PLS Workflow with Enhanced Detector V4
======================================
‡πÉ‡∏ä‡πâ Enhanced Detector V4 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ detect peak ‡πÅ‡∏•‡∏∞ baseline ‡∏ó‡∏µ‡πà‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥‡πÄ‡∏Å‡∏∑‡∏≠‡∏ö 100%
‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå PLS ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• CV
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from pathlib import Path
import re
import json
import logging
from datetime import datetime
from sklearn.cross_decomposition import PLSRegression
from sklearn.model_selection import cross_val_score, KFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error

# Import Enhanced Detector V4
try:
    from enhanced_detector_v4 import EnhancedDetectorV4
    ENHANCED_V4_AVAILABLE = True
    print("‚úÖ Enhanced Detector V4 ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
except ImportError:
    ENHANCED_V4_AVAILABLE = False
    print("‚ùå Enhanced Detector V4 ‡πÑ‡∏°‡πà‡∏û‡∏ö")
    exit(1)

# Setup logging
logging.basicConfig(level=logging.INFO, format='%(levelname)s: %(message)s')
logger = logging.getLogger(__name__)

class PLSWorkflowV4:
    """
    PLS Workflow ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ Enhanced Detector V4
    """
    
    def __init__(self, palmsens_dir="Test_data/Palmsens", stm32_dir="Test_data/Stm32", output_dir="pls_results_v4"):
        self.palmsens_dir = Path(palmsens_dir)
        self.stm32_dir = Path(stm32_dir)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        # Initialize Enhanced Detector V4
        self.detector = EnhancedDetectorV4()
        
        self.results = {
            'data_matrix': [],
            'concentrations': [],
            'scan_rates': [],
            'peak_data': {},
            'missing_combinations': [],
            'detection_stats': {
                'total_files': 0,
                'successful_detections': 0,
                'failed_detections': 0,
                'high_confidence_detections': 0
            }
        }
    
    def extract_metadata_from_filename(self, filename):
        """‡πÅ‡∏¢‡∏Å concentration ‡πÅ‡∏•‡∏∞ scan rate ‡∏à‡∏≤‡∏Å filename"""
        filename_lower = filename.lower()
        
        # Pattern ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö concentration
        concentration = None
        
        # Palmsens format: Palmsens_0.5mM_...
        conc_match = re.search(r'palmsens[_\s]*(\d+\.?\d*)\s*mm', filename_lower)
        if conc_match:
            concentration = float(conc_match.group(1))
        
        # STM32 format: Pipot_Ferro_0_5mM_... ‡∏´‡∏£‡∏∑‡∏≠ Pipot_Ferro_1_0mM_...
        if concentration is None:
            conc_match = re.search(r'pipot[_\s]*ferro[_\s]*(\d+)[_\s]*(\d+)[_\s]*mm', filename_lower)
            if conc_match:
                major = int(conc_match.group(1))
                minor = int(conc_match.group(2))
                concentration = major + minor / 10.0
        
        # Pattern ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö scan rate
        scan_rate = None
        scan_match = re.search(r'(\d+\.?\d*)\s*mv[\/\s]*p?s', filename_lower)
        if scan_match:
            scan_rate = float(scan_match.group(1))
        
        return concentration, scan_rate
    
    def load_cv_file(self, filepath, device_type):
        """‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå CV ‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏î‡πâ‡∏ß‡∏¢ Enhanced Detector V4"""
        try:
            self.results['detection_stats']['total_files'] += 1
            
            # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• - skip 2 ‡∏ö‡∏£‡∏£‡∏ó‡∏±‡∏î‡πÅ‡∏£‡∏Å (‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå + header)
            if device_type == 'palmsens':
                # Palmsens CSV format: skip 2 lines (filename + column headers), V,uA columns
                data = pd.read_csv(filepath, skiprows=2, names=['voltage', 'current'])
            else:
                # STM32 format - assume similar structure with 2 header lines
                data = pd.read_csv(filepath, skiprows=2, names=['voltage', 'current'])
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            if len(data) == 0:
                logger.warning(f"   ‚ùå ‡πÑ‡∏ü‡∏•‡πå‡∏ß‡πà‡∏≤‡∏á: {filepath.name}")
                self.results['detection_stats']['failed_detections'] += 1
                return None
            
            voltage = data['voltage'].values
            current = data['current'].values
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏Ç
            if not (np.isfinite(voltage).all() and np.isfinite(current).all()):
                logger.warning(f"   ‚ùå ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á: {filepath.name}")
                self.results['detection_stats']['failed_detections'] += 1
                return None
            
            # ‡πÉ‡∏ä‡πâ Enhanced Detector V4 ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå
            logger.info(f"üî¨ ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå {filepath.name} ‡∏î‡πâ‡∏ß‡∏¢ Enhanced Detector V4...")
            
            # ‡∏™‡∏£‡πâ‡∏≤‡∏á data structure ‡∏ó‡∏µ‡πà Enhanced V4 ‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
            cv_data_dict = {
                'voltage': voltage,
                'current': current
            }
            
            # ‡∏£‡∏±‡∏ô Enhanced Detector V4
            results = self.detector.analyze_cv_data(cv_data_dict)
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
            if results and 'confidence' in results:
                confidence = results.get('confidence', 0)
                
                # ‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• peaks
                peak_data = results.get('peak_data', {})
                oxidation_peak = peak_data.get('oxidation_peak')
                reduction_peak = peak_data.get('reduction_peak')
                
                # ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• baseline
                baseline_data = results.get('baseline_data', {})
                
                # Peak heights ‡πÅ‡∏•‡∏∞ areas
                ox_height = oxidation_peak.get('height') if oxidation_peak else None
                red_height = abs(reduction_peak.get('height')) if reduction_peak else None
                
                ox_area = oxidation_peak.get('area') if oxidation_peak else None
                red_area = abs(reduction_peak.get('area')) if reduction_peak else None
                
                # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ peak ‡∏Ñ‡∏£‡∏ö‡∏ó‡∏±‡πâ‡∏á 2 ‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
                has_both_peaks = (ox_height is not None and red_height is not None and 
                                ox_area is not None and red_area is not None)
                
                if confidence >= 70:  # High confidence
                    self.results['detection_stats']['high_confidence_detections'] += 1
                
                if has_both_peaks:
                    self.results['detection_stats']['successful_detections'] += 1
                else:
                    self.results['detection_stats']['failed_detections'] += 1
                
                logger.info(f"   ‚úÖ Confidence: {confidence:.1f}%, Peaks: {'‚úÖ' if has_both_peaks else '‚ùå'}")
                
                return {
                    'voltage': voltage,
                    'current': current,
                    'enhanced_v4_results': results,
                    'confidence': confidence,
                    'anodic_peak': ox_height,
                    'cathodic_peak': red_height,
                    'anodic_area': ox_area,
                    'cathodic_area': red_area,
                    'has_both_peaks': has_both_peaks,
                    'peak_data': peak_data,
                    'baseline_data': baseline_data
                }
            else:
                logger.warning(f"   ‚ùå Enhanced V4 ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏î‡πâ")
                self.results['detection_stats']['failed_detections'] += 1
                return None
                
        except Exception as e:
            logger.error(f"‚ùå Error loading {filepath}: {e}")
            self.results['detection_stats']['failed_detections'] += 1
            return None
    
    def scan_data_files(self, max_files_per_combination=3):
        """‡∏™‡πÅ‡∏Å‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• CV ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏≤‡∏Å Palmsens ‡πÅ‡∏•‡∏∞ STM32"""
        all_files = []
        
        # ‡∏™‡πÅ‡∏Å‡∏ô‡πÑ‡∏ü‡∏•‡πå Palmsens
        if self.palmsens_dir.exists():
            for conc_folder in self.palmsens_dir.iterdir():
                if conc_folder.is_dir():
                    csv_files = list(conc_folder.glob("*.csv"))
                    for f in csv_files:
                        all_files.append((f, 'palmsens'))
        
        # ‡∏™‡πÅ‡∏Å‡∏ô‡πÑ‡∏ü‡∏•‡πå STM32
        if self.stm32_dir.exists():
            for conc_folder in self.stm32_dir.iterdir():
                if conc_folder.is_dir():
                    csv_files = list(conc_folder.glob("*.csv"))
                    for f in csv_files:
                        all_files.append((f, 'stm32'))
        
        print(f"üîç ‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {len(all_files)} ‡πÑ‡∏ü‡∏•‡πå")
        print(f"   - Palmsens: {len([f for f, t in all_files if t == 'palmsens'])} ‡πÑ‡∏ü‡∏•‡πå")
        print(f"   - STM32: {len([f for f, t in all_files if t == 'stm32'])} ‡πÑ‡∏ü‡∏•‡πå")
        
        data_matrix = []
        concentrations = set()
        scan_rates = set()
        combination_counts = {}
        
        for filepath, device_type in all_files:
            # ‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• metadata
            concentration, scan_rate = self.extract_metadata_from_filename(filepath.name)
            
            if concentration is None or scan_rate is None:
                continue
            
            # ‡∏à‡∏≥‡∏Å‡∏±‡∏î‡∏à‡∏≥‡∏ô‡∏ß‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏ï‡πà‡∏≠ combination
            combo_key = (concentration, scan_rate, device_type)
            if combo_key not in combination_counts:
                combination_counts[combo_key] = 0
            
            if combination_counts[combo_key] >= max_files_per_combination:
                continue
            
            combination_counts[combo_key] += 1
            
            # ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏ü‡∏•‡πå
            cv_data = self.load_cv_file(filepath, device_type)
            if cv_data is None:
                continue
            
            # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            row = {
                'filename': filepath.name,
                'filepath': str(filepath),
                'device_type': device_type,
                'concentration': concentration,
                'scan_rate': scan_rate,
                'anodic_peak': cv_data['anodic_peak'],
                'cathodic_peak': cv_data['cathodic_peak'], 
                'anodic_area': cv_data['anodic_area'],
                'cathodic_area': cv_data['cathodic_area'],
                'has_both_peaks': cv_data['has_both_peaks'],
                'confidence': cv_data['confidence'],
                'enhanced_v4_results': cv_data['enhanced_v4_results']
            }
            
            data_matrix.append(row)
            concentrations.add(concentration)
            scan_rates.add(scan_rate)
        
        self.results['data_matrix'] = data_matrix
        self.results['concentrations'] = sorted(concentrations)
        self.results['scan_rates'] = sorted(scan_rates)
        
        return pd.DataFrame(data_matrix)
    
    def create_data_availability_table(self, df_all):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡∏°‡∏µ"""
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á concentration vs scan_rate ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÅ‡∏ï‡πà‡∏•‡∏∞ device
        availability_table = []
        missing_combinations = []
        
        for device in ['palmsens', 'stm32']:
            device_data = df_all[df_all['device_type'] == device]
            
            for conc in self.results['concentrations']:
                for scan in self.results['scan_rates']:
                    subset = device_data[(device_data['concentration'] == conc) & 
                                       (device_data['scan_rate'] == scan)]
                    valid_peaks = subset[subset['has_both_peaks'] == True]
                    
                    if len(valid_peaks) > 0:
                        # ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ
                        best_sample = valid_peaks.loc[valid_peaks['confidence'].idxmax()]
                        availability_table.append({
                            'device_type': device,
                            'concentration': conc,
                            'scan_rate': scan, 
                            'available': True,
                            'filename': best_sample['filename'],
                            'confidence': best_sample['confidence'],
                            'anodic_peak': best_sample['anodic_peak'],
                            'cathodic_peak': best_sample['cathodic_peak']
                        })
                    else:
                        # ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ peak ‡∏Ñ‡∏£‡∏ö
                        missing_combinations.append({
                            'device_type': device,
                            'concentration': conc,
                            'scan_rate': scan,
                            'available': False,
                            'reason': 'No data with both peaks'
                        })
                        availability_table.append({
                            'device_type': device,
                            'concentration': conc,
                            'scan_rate': scan,
                            'available': False, 
                            'filename': None,
                            'confidence': 0,
                            'anodic_peak': None,
                            'cathodic_peak': None
                        })
        
        self.results['missing_combinations'] = missing_combinations
        return pd.DataFrame(availability_table)
    
    def perform_pls_analysis(self, df_availability, device_type='palmsens'):
        """‡∏ó‡∏≥ PLS analysis ‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ"""
        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ peak ‡∏Ñ‡∏£‡∏ö‡πÅ‡∏•‡∏∞ device ‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£
        valid_data = df_availability[
            (df_availability['available'] == True) & 
            (df_availability['device_type'] == device_type)
        ].copy()
        
        if len(valid_data) < 5:
            print(f"‚ùå ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {device_type} ‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö PLS analysis (‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 5 samples)")
            return None
        
        print(f"üß† ‡∏ó‡∏≥ PLS Analysis ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö {device_type} ({len(valid_data)} samples)...")
        
        # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        X = valid_data[['anodic_peak', 'cathodic_peak']].values
        y = valid_data['concentration'].values
        
        # Scaling
        scaler_X = StandardScaler()
        scaler_y = StandardScaler()
        
        X_scaled = scaler_X.fit_transform(X)
        y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).ravel()
        
        # PLS Model
        n_components = min(2, X.shape[1], len(y) - 1)
        pls = PLSRegression(n_components=n_components)
        pls.fit(X_scaled, y_scaled)
        
        # Prediction
        y_pred_scaled = pls.predict(X_scaled)
        y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()
        
        # Cross-validation
        cv_folds = min(5, len(y))
        cv_scores = cross_val_score(pls, X_scaled, y_scaled, cv=cv_folds, scoring='r2')
        
        # Metrics
        r2 = r2_score(y, y_pred)
        rmse = np.sqrt(mean_squared_error(y, y_pred))
        mae = mean_absolute_error(y, y_pred)
        
        results = {
            'device_type': device_type,
            'model': pls,
            'scaler_X': scaler_X,
            'scaler_y': scaler_y,
            'X': X,
            'y': y,
            'y_pred': y_pred,
            'r2': r2,
            'rmse': rmse,
            'mae': mae,
            'cv_scores': cv_scores,
            'cv_mean': cv_scores.mean(),
            'cv_std': cv_scores.std(),
            'n_samples': len(valid_data),
            'n_components': n_components
        }
        
        return results
    
    def create_visualizations(self, pls_results_palmsens, pls_results_stm32, df_availability):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á Palmsens ‡πÅ‡∏•‡∏∞ STM32"""
        fig, axes = plt.subplots(3, 2, figsize=(15, 18))
        
        devices = [('palmsens', pls_results_palmsens), ('stm32', pls_results_stm32)]
        colors = ['blue', 'red']
        
        for col, (device, pls_results) in enumerate(devices):
            if pls_results is None:
                continue
                
            device_name = device.upper()
            color = colors[col]
            
            # 1. Prediction vs Actual
            ax1 = axes[0, col]
            y = pls_results['y']
            y_pred = pls_results['y_pred']
            
            ax1.scatter(y, y_pred, alpha=0.7, s=60, color=color)
            min_val, max_val = min(y.min(), y_pred.min()), max(y.max(), y_pred.max())
            ax1.plot([min_val, max_val], [min_val, max_val], 'k--', lw=2)
            ax1.set_xlabel('Actual Concentration (mM)')
            ax1.set_ylabel('Predicted Concentration (mM)')
            ax1.set_title(f'{device_name} PLS Prediction vs Actual\nR¬≤ = {pls_results["r2"]:.3f}')
            ax1.grid(True, alpha=0.3)
            
            # 2. Residuals
            ax2 = axes[1, col]
            residuals = y - y_pred
            ax2.scatter(y_pred, residuals, alpha=0.7, color=color)
            ax2.axhline(y=0, color='k', linestyle='--')
            ax2.set_xlabel('Predicted Concentration (mM)')
            ax2.set_ylabel('Residuals')
            ax2.set_title(f'{device_name} Residual Plot')
            ax2.grid(True, alpha=0.3)
            
            # 3. PLS Loadings
            ax3 = axes[2, col]
            loadings = pls_results['model'].x_loadings_[:, 0]
            features = ['Anodic Peak', 'Cathodic Peak']
            bars = ax3.bar(features, loadings, color=[color if l >= 0 else 'orange' for l in loadings])
            ax3.set_ylabel('Loading Value')
            ax3.set_title(f'{device_name} PLS X-Loadings (Component 1)')
            ax3.grid(True, alpha=0.3)
        
        plt.tight_layout()
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏π‡∏õ
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        output_path = self.output_dir / f"pls_analysis_enhanced_v4_{timestamp}.png"
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        print(f"üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà: {output_path}")
        
        plt.show()
        
        return output_path
    
    def print_detection_stats(self):
        """‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£ detect ‡∏Ç‡∏≠‡∏á Enhanced V4"""
        stats = self.results['detection_stats']
        
        print(f"\nüìä ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£ detect ‡∏î‡πâ‡∏ß‡∏¢ Enhanced Detector V4:")
        print(f"   üìÅ ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {stats['total_files']}")
        print(f"   ‚úÖ Detect ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {stats['successful_detections']} ({stats['successful_detections']/stats['total_files']*100:.1f}%)")
        print(f"   ‚ùå Detect ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à: {stats['failed_detections']} ({stats['failed_detections']/stats['total_files']*100:.1f}%)")
        print(f"   üéØ Confidence ‡∏™‡∏π‡∏á (‚â•70%): {stats['high_confidence_detections']} ({stats['high_confidence_detections']/stats['total_files']*100:.1f}%)")
    
    def run_workflow(self):
        """‡∏£‡∏±‡∏ô workflow ‡∏´‡∏•‡∏±‡∏Å"""
        print("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô PLS Workflow ‡∏î‡πâ‡∏ß‡∏¢ Enhanced Detector V4")
        print("=" * 60)
        
        # 1. ‡∏™‡πÅ‡∏Å‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        print("\nüìÇ 1. ‡∏™‡πÅ‡∏Å‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• CV...")
        df_all = self.scan_data_files(max_files_per_combination=3)
        print(f"   ‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {len(df_all)} ‡πÑ‡∏ü‡∏•‡πå")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏Å‡∏≤‡∏£ detect
        self.print_detection_stats()
        
        # 2. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        print("\nüìä 2. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
        df_availability = self.create_data_availability_table(df_all)
        
        # 3. ‡∏ó‡∏≥ PLS Analysis ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á Palmsens ‡πÅ‡∏•‡∏∞ STM32
        print("\nüß† 3. ‡∏ó‡∏≥ PLS Analysis...")
        
        pls_palmsens = self.perform_pls_analysis(df_availability, 'palmsens')
        pls_stm32 = self.perform_pls_analysis(df_availability, 'stm32')
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        if pls_palmsens:
            print(f"\nüìà Palmsens Results:")
            print(f"   R¬≤ = {pls_palmsens['r2']:.3f}")
            print(f"   RMSE = {pls_palmsens['rmse']:.3f} mM")
            print(f"   CV R¬≤ = {pls_palmsens['cv_mean']:.3f} ¬± {pls_palmsens['cv_std']:.3f}")
        
        if pls_stm32:
            print(f"\nüìà STM32 Results:")
            print(f"   R¬≤ = {pls_stm32['r2']:.3f}")
            print(f"   RMSE = {pls_stm32['rmse']:.3f} mM")
            print(f"   CV R¬≤ = {pls_stm32['cv_mean']:.3f} ¬± {pls_stm32['cv_std']:.3f}")
        
        # 4. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
        if pls_palmsens or pls_stm32:
            print("\nüìä 4. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•...")
            self.create_visualizations(pls_palmsens, pls_stm32, df_availability)
        
        # 5. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        print("\nüíæ 5. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå...")
        self.save_results(df_availability, pls_palmsens, pls_stm32)
        
        print("\n‚úÖ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô PLS Workflow ‡∏î‡πâ‡∏ß‡∏¢ Enhanced Detector V4!")
        return pls_palmsens, pls_stm32, df_availability
    
    def save_results(self, df_availability, pls_palmsens, pls_stm32):
        """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å data availability
        availability_path = self.output_dir / f"data_availability_v4_{timestamp}.csv"
        df_availability.to_csv(availability_path, index=False)
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å summary report
        report_path = self.output_dir / f"pls_report_v4_{timestamp}.txt"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("PLS Analysis Report - Enhanced Detector V4\n")
            f.write("==========================================\n\n")
            f.write(f"Analysis Date: {datetime.now()}\n")
            f.write(f"Method: Enhanced Detector V4\n\n")
            
            # Detection stats
            stats = self.results['detection_stats']
            f.write("Detection Statistics:\n")
            f.write(f"- Total files processed: {stats['total_files']}\n")
            f.write(f"- Successful detections: {stats['successful_detections']} ({stats['successful_detections']/stats['total_files']*100:.1f}%)\n")
            f.write(f"- High confidence detections: {stats['high_confidence_detections']} ({stats['high_confidence_detections']/stats['total_files']*100:.1f}%)\n\n")
            
            f.write("Data Summary:\n")
            f.write(f"- Total concentrations: {len(self.results['concentrations'])}\n")
            f.write(f"- Total scan rates: {len(self.results['scan_rates'])}\n")
            f.write(f"- Available combinations: {len(df_availability[df_availability['available']])}\n\n")
            
            if pls_palmsens:
                f.write("Palmsens PLS Results:\n")
                f.write(f"- R¬≤ = {pls_palmsens['r2']:.3f}\n")
                f.write(f"- RMSE = {pls_palmsens['rmse']:.3f} mM\n")
                f.write(f"- CV R¬≤ = {pls_palmsens['cv_mean']:.3f} ¬± {pls_palmsens['cv_std']:.3f}\n")
                f.write(f"- Samples used = {pls_palmsens['n_samples']}\n\n")
            
            if pls_stm32:
                f.write("STM32 PLS Results:\n")
                f.write(f"- R¬≤ = {pls_stm32['r2']:.3f}\n")
                f.write(f"- RMSE = {pls_stm32['rmse']:.3f} mM\n")
                f.write(f"- CV R¬≤ = {pls_stm32['cv_mean']:.3f} ¬± {pls_stm32['cv_std']:.3f}\n")
                f.write(f"- Samples used = {pls_stm32['n_samples']}\n\n")
        
        print(f"   üíæ Data availability: {availability_path}")
        print(f"   üíæ Report: {report_path}")


# ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô
if __name__ == "__main__":
    if not ENHANCED_V4_AVAILABLE:
        print("‚ùå Enhanced Detector V4 ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
        exit(1)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á workflow
    workflow = PLSWorkflowV4(
        palmsens_dir="Test_data/Palmsens",    # Reference potentiostat
        stm32_dir="Test_data/Stm32",          # Target potentiostat  
        output_dir="pls_results_v4"
    )
    
    # ‡∏£‡∏±‡∏ô workflow
    pls_palmsens, pls_stm32, df_availability = workflow.run_workflow()
    
    # ‡∏™‡∏£‡∏∏‡∏õ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
    if pls_palmsens or pls_stm32:
        print("\nüéâ PLS Analysis ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
        if pls_palmsens:
            print(f"   Palmsens: R¬≤ = {pls_palmsens['r2']:.3f}")
        if pls_stm32:
            print(f"   STM32: R¬≤ = {pls_stm32['r2']:.3f}")
    else:
        print("\n‚ùå PLS Analysis ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à - ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠")
