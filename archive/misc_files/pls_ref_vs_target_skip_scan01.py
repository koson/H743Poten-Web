#!/usr/bin/env python3
"""
PLS Analysis: Palmsens (Reference) vs STM32 (Target)
‡∏Ç‡πâ‡∏≤‡∏° scan_01 ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏£‡∏∞‡∏ö‡∏ö‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£ (‡πÉ‡∏ä‡πâ scan_02 ‡πÄ‡∏õ‡πá‡∏ô‡∏ï‡πâ‡∏ô‡πÑ‡∏õ)
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.cross_decomposition import PLSRegression
from sklearn.model_selection import cross_val_score, train_test_split
from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error
from sklearn.preprocessing import StandardScaler
import os
import glob
import re
from pathlib import Path
import time
from datetime import datetime
import json

def should_skip_file(filename):
    """Check if file should be skipped (scan_01 files)"""
    return 'scan_01' in filename.lower()

def filter_valid_files(file_list):
    """Filter out scan_01 files and keep only stable measurements"""
    valid_files = [f for f in file_list if not should_skip_file(str(f))]
    skipped_count = len(file_list) - len(valid_files)
    
    if skipped_count > 0:
        print(f"‚ö†Ô∏è ‡∏Ç‡πâ‡∏≤‡∏° scan_01: {skipped_count} ‡πÑ‡∏ü‡∏•‡πå (‡∏£‡∏∞‡∏ö‡∏ö‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£)")
        
    return valid_files

def extract_metadata_from_filename(filename):
    """‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• metadata ‡∏à‡∏≤‡∏Å‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå"""
    filename_only = Path(filename).stem
    
    # Example: "Palmsens_0.5mM_CV_100mVpS_E1_scan_02.csv"
    patterns = [
        r'(\w+)_([0-9.]+mM)_CV_([0-9.]+mVpS)_(\w+)_scan_(\d+)',
        r'(\w+)_([0-9.]+)mM_CV_([0-9.]+)mVs_(\w+)_scan_(\d+)',
        r'(\w+)_([0-9.]+mM)_([0-9.]+mVpS)_(\w+)_scan_(\d+)',
    ]
    
    for pattern in patterns:
        match = re.search(pattern, filename_only)
        if match:
            groups = match.groups()
            device = groups[0]
            concentration_str = groups[1]
            scan_rate_str = groups[2]
            electrode = groups[3]
            scan_number = groups[4]
            
            # Extract numeric values
            conc_match = re.search(r'([0-9.]+)', concentration_str)
            concentration = float(conc_match.group(1)) if conc_match else 0.0
            
            rate_match = re.search(r'([0-9.]+)', scan_rate_str)
            scan_rate = float(rate_match.group(1)) if rate_match else 0.0
            
            return {
                'device': device,
                'concentration': concentration,
                'scan_rate': scan_rate,
                'electrode': electrode,
                'scan_number': int(scan_number),
                'filename': filename_only
            }
    
    return {
        'device': 'unknown',
        'concentration': 0.0,
        'scan_rate': 0.0,
        'electrode': 'unknown',
        'scan_number': 1,
        'filename': filename_only
    }

def analyze_cv_file_enhanced_v4(filepath, detector):
    """‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏ü‡∏•‡πå CV ‡∏î‡πâ‡∏ß‡∏¢ Enhanced V4 Improved"""
    try:
        # ‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå (skip 2 header rows)
        data = pd.read_csv(filepath, skiprows=2, names=['voltage', 'current'])
        
        if data.empty or len(data) < 10:
            return None
        
        # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Enhanced V4 Improved
        cv_data = {
            'voltage': data['voltage'].tolist(),
            'current': data['current'].tolist()
        }
        
        # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡∏î‡πâ‡∏ß‡∏¢ Enhanced V4 Improved
        results = detector.analyze_cv_data(cv_data)
        
        if not results or not isinstance(results, dict):
            return None
        
        # ‡πÅ‡∏¢‡∏Å peaks
        all_peaks = results.get('peaks', [])
        if not all_peaks:
            return None
        
        anodic_peaks = [p for p in all_peaks if p.get('type') == 'oxidation']
        cathodic_peaks = [p for p in all_peaks if p.get('type') == 'reduction']
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ peak ‡∏Ñ‡∏£‡∏ö‡∏ó‡∏±‡πâ‡∏á 2 ‡∏î‡πâ‡∏≤‡∏ô
        has_both_peaks = len(anodic_peaks) > 0 and len(cathodic_peaks) > 0
        
        if not has_both_peaks:
            return None
        
        # Extract metadata
        metadata = extract_metadata_from_filename(filepath.name)
        
        # Extract peak features
        ox_peak = anodic_peaks[0]  # ‡πÉ‡∏ä‡πâ peak ‡πÅ‡∏£‡∏Å
        red_peak = cathodic_peaks[0]  # ‡πÉ‡∏ä‡πâ peak ‡πÅ‡∏£‡∏Å
        
        peak_features = {
            'ox_voltage': ox_peak.get('voltage', 0),
            'ox_current': ox_peak.get('current', 0),
            'ox_confidence': ox_peak.get('confidence', 0),
            'red_voltage': red_peak.get('voltage', 0),
            'red_current': red_peak.get('current', 0),
            'red_confidence': red_peak.get('confidence', 0),
            
            # Derived features
            'peak_separation_voltage': abs(ox_peak.get('voltage', 0) - red_peak.get('voltage', 0)),
            'peak_separation_current': abs(ox_peak.get('current', 0) - red_peak.get('current', 0)),
            'current_ratio': ox_peak.get('current', 0) / red_peak.get('current', 0) if red_peak.get('current', 0) != 0 else 0,
            'midpoint_potential': (ox_peak.get('voltage', 0) + red_peak.get('voltage', 0)) / 2
        }
        
        return {
            'filename': filepath.name,
            'metadata': metadata,
            'peak_features': peak_features,
            'has_both_peaks': has_both_peaks,
            'peak_count': len(all_peaks)
        }
        
    except Exception as e:
        print(f"‚ùå Error analyzing {filepath.name}: {e}")
        return None

def collect_data_from_directory(data_dir, detector, device_name):
    """‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡πÑ‡∏î‡πÄ‡∏£‡∏Å‡∏ó‡∏≠‡∏£‡∏µ (‡∏Ç‡πâ‡∏≤‡∏° scan_01)"""
    print(f"üìÅ ‡∏™‡πÅ‡∏Å‡∏ô‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô {data_dir} ({device_name})...")
    
    if not os.path.exists(data_dir):
        print(f"‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡πÑ‡∏î‡πÄ‡∏£‡∏Å‡∏ó‡∏≠‡∏£‡∏µ: {data_dir}")
        return []
    
    # ‡∏´‡∏≤‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î
    pattern = os.path.join(data_dir, "**", "*.csv")
    all_files = [Path(f) for f in glob.glob(pattern, recursive=True)]
    
    # ‡∏Å‡∏£‡∏≠‡∏á‡πÑ‡∏ü‡∏•‡πå (‡∏Ç‡πâ‡∏≤‡∏° scan_01)
    valid_files = filter_valid_files(all_files)
    
    print(f"üìä ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î: {len(all_files)}, ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ: {len(valid_files)} (‡∏Ç‡πâ‡∏≤‡∏° scan_01: {len(all_files) - len(valid_files)})")
    
    # ‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏ü‡∏•‡πå
    valid_data = []
    stats = {'total': 0, 'success': 0, 'failed': 0, 'both_peaks': 0}
    
    for i, filepath in enumerate(valid_files):
        print(f"[{i+1:2d}/{len(valid_files)}] {filepath.name}...", end=" ")
        
        stats['total'] += 1
        result = analyze_cv_file_enhanced_v4(filepath, detector)
        
        if result and result['has_both_peaks']:
            valid_data.append(result)
            stats['success'] += 1
            stats['both_peaks'] += 1
            
            pf = result['peak_features']
            print(f"‚úÖ ox:{pf['ox_voltage']:.3f}V, red:{pf['red_voltage']:.3f}V, sep:{pf['peak_separation_voltage']:.3f}V")
        else:
            stats['failed'] += 1
            print("‚ùå no valid peaks")
    
    print(f"üìà {device_name} ‡∏™‡∏£‡∏∏‡∏õ: {stats['success']}/{stats['total']} ‡πÑ‡∏ü‡∏•‡πå‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ ({stats['success']/stats['total']*100:.1f}%)")
    
    return valid_data

def run_pls_analysis_ref_vs_target():
    """‡∏£‡∏±‡∏ô PLS Analysis: Palmsens (ref) vs STM32 (target) - ‡∏Ç‡πâ‡∏≤‡∏° scan_01"""
    print("üéØ PLS Analysis: Palmsens (REF) vs STM32 (TARGET)")
    print("‚ö†Ô∏è ‡∏Ç‡πâ‡∏≤‡∏° scan_01 ‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏£‡∏∞‡∏ö‡∏ö‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡πÄ‡∏™‡∏ñ‡∏µ‡∏¢‡∏£")
    print("=" * 60)
    
    try:
        from enhanced_detector_v4_improved import EnhancedDetectorV4Improved
        print("‚úÖ Enhanced V4 Improved ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
    except ImportError:
        print("‚ùå Enhanced V4 Improved ‡πÑ‡∏°‡πà‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
        return
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á detector
    detector = EnhancedDetectorV4Improved(confidence_threshold=25.0)
    
    # ‡∏Å‡∏≥‡∏´‡∏ô‡∏î directories
    ref_dir = "Test_data/Palmsens"
    target_dir = "Test_data/Stm32"
    
    start_time = time.time()
    
    # ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Reference (Palmsens)
    print("\nüî¨ ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Reference (Palmsens)...")
    ref_data = collect_data_from_directory(ref_dir, detector, "Palmsens")
    
    # ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Target (STM32)
    print("\nüéØ ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Target (STM32)...")
    target_data = collect_data_from_directory(target_dir, detector, "STM32")
    
    collection_time = time.time() - start_time
    print(f"\n‚è±Ô∏è ‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏£‡πá‡∏à‡πÉ‡∏ô {collection_time:.2f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ")
    
    if not ref_data:
        print("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Reference (Palmsens)")
        return
    
    if not target_data:
        print("‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Target (STM32)")
        return
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏≤‡∏¢‡∏á‡∏≤‡∏ô‡∏™‡∏£‡∏∏‡∏õ
    print(f"\nüìä ‡∏™‡∏£‡∏∏‡∏õ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏£‡∏ß‡∏ö‡∏£‡∏ß‡∏°‡πÑ‡∏î‡πâ:")
    print(f"  Reference (Palmsens): {len(ref_data)} ‡πÑ‡∏ü‡∏•‡πå")
    print(f"  Target (STM32): {len(target_data)} ‡πÑ‡∏ü‡∏•‡πå")
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏Å‡∏≤‡∏£‡∏Å‡∏£‡∏∞‡∏à‡∏≤‡∏¢‡∏Ç‡∏≠‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏°‡∏Ç‡πâ‡∏ô
    ref_concentrations = [d['metadata']['concentration'] for d in ref_data]
    target_concentrations = [d['metadata']['concentration'] for d in target_data]
    
    print(f"  Palmsens ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏°‡∏Ç‡πâ‡∏ô: {sorted(set(ref_concentrations))} mM")
    print(f"  STM32 ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏°‡∏Ç‡πâ‡∏ô: {sorted(set(target_concentrations))} mM")
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö analysis
    create_pls_dataframes_and_analysis(ref_data, target_data)
    
    # Export ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
    export_pls_data_with_labplot2(ref_data, target_data)
    
    print(f"\nüéâ PLS Analysis ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô!")

def create_pls_dataframes_and_analysis(ref_data, target_data):
    """‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå PLS"""
    print("\nüìà ‡∏™‡∏£‡πâ‡∏≤‡∏á PLS DataFrames ‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå...")
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Reference
    ref_rows = []
    for data in ref_data:
        row = data['metadata'].copy()
        row.update(data['peak_features'])
        row['device'] = 'Palmsens'
        ref_rows.append(row)
    
    ref_df = pd.DataFrame(ref_rows)
    
    # ‡∏™‡∏£‡πâ‡∏≤‡∏á DataFrame ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Target
    target_rows = []
    for data in target_data:
        row = data['metadata'].copy()
        row.update(data['peak_features'])
        row['device'] = 'STM32'
        target_rows.append(row)
    
    target_df = pd.DataFrame(target_rows)
    
    print(f"‚úÖ Reference DataFrame: {len(ref_df)} samples")
    print(f"‚úÖ Target DataFrame: {len(target_df)} samples")
    
    # ‡πÅ‡∏™‡∏î‡∏á‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô
    print(f"\nüìä ‡∏™‡∏ñ‡∏¥‡∏ï‡∏¥‡∏û‡∏∑‡πâ‡∏ô‡∏ê‡∏≤‡∏ô:")
    print(f"Palmsens - ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏°‡∏Ç‡πâ‡∏ô‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢: {ref_df['concentration'].mean():.2f}¬±{ref_df['concentration'].std():.2f} mM")
    print(f"STM32 - ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏°‡∏Ç‡πâ‡∏ô‡πÄ‡∏â‡∏•‡∏µ‡πà‡∏¢: {target_df['concentration'].mean():.2f}¬±{target_df['concentration'].std():.2f} mM")
    
    # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å DataFrames
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    ref_path = f"pls_reference_palmsens_{timestamp}.csv"
    target_path = f"pls_target_stm32_{timestamp}.csv"
    
    ref_df.to_csv(ref_path, index=False)
    target_df.to_csv(target_path, index=False)
    
    print(f"üìÑ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Reference data: {ref_path}")
    print(f"üìÑ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å Target data: {target_path}")
    
    return ref_df, target_df

def export_pls_data_with_labplot2(ref_data, target_data):
    """Export ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà LabPlot2 ‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ"""
    print("\nüìä Export ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö LabPlot2...")
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # Combined data for PLS analysis
    combined_data = []
    
    # Add reference data
    for data in ref_data:
        row = {
            'device': 'Palmsens',
            'device_code': 0,  # Numeric code for LabPlot2
            **data['metadata'],
            **data['peak_features']
        }
        combined_data.append(row)
    
    # Add target data  
    for data in target_data:
        row = {
            'device': 'STM32',
            'device_code': 1,  # Numeric code for LabPlot2
            **data['metadata'],
            **data['peak_features']
        }
        combined_data.append(row)
    
    # Create DataFrame
    df = pd.DataFrame(combined_data)
    
    # LabPlot2 compatible CSV with metadata
    labplot_filename = f"pls_data_labplot2_compatible_{timestamp}.csv"
    
    # Write with LabPlot2 metadata header
    with open(labplot_filename, 'w', encoding='utf-8') as f:
        # LabPlot2 metadata comments
        f.write("# LabPlot2 Data File\n")
        f.write("# PLS Analysis: Palmsens (Reference) vs STM32 (Target)\n")
        f.write(f"# Generated: {datetime.now().isoformat()}\n")
        f.write("# Method: Enhanced Detector V4 Improved\n")
        f.write("# Note: scan_01 files excluded (system not stable)\n")
        f.write("#\n")
        f.write("# Column descriptions:\n")
        f.write("# device: Device name (Palmsens/STM32)\n")
        f.write("# device_code: Numeric device code (0=Palmsens, 1=STM32)\n")
        f.write("# concentration: Ferrocyanide concentration (mM)\n")
        f.write("# scan_rate: CV scan rate (mV/s)\n")
        f.write("# ox_voltage: Oxidation peak voltage (V)\n")
        f.write("# ox_current: Oxidation peak current (¬µA)\n")
        f.write("# red_voltage: Reduction peak voltage (V)\n")
        f.write("# red_current: Reduction peak current (¬µA)\n")
        f.write("# peak_separation_voltage: |ox_voltage - red_voltage| (V)\n")
        f.write("# current_ratio: ox_current / red_current\n")
        f.write("# midpoint_potential: (ox_voltage + red_voltage) / 2 (V)\n")
        f.write("#\n")
        
        # Write CSV data
        df.to_csv(f, index=False)
    
    print(f"üìä LabPlot2 compatible file: {labplot_filename}")
    print(f"üìà Total samples: {len(df)} ({len(ref_data)} Palmsens + {len(target_data)} STM32)")
    print(f"üîç Columns: {list(df.columns)}")
    
    # Summary statistics for report
    summary = {
        'timestamp': timestamp,
        'ref_samples': len(ref_data),
        'target_samples': len(target_data),
        'total_samples': len(df),
        'scan_01_skipped': True,
        'ref_concentrations': sorted(df[df['device'] == 'Palmsens']['concentration'].unique()),
        'target_concentrations': sorted(df[df['device'] == 'STM32']['concentration'].unique()),
        'method': 'Enhanced Detector V4 Improved',
        'files': {
            'labplot2_csv': labplot_filename,
            'ref_csv': f"pls_reference_palmsens_{timestamp}.csv",
            'target_csv': f"pls_target_stm32_{timestamp}.csv"
        }
    }
    
    # Save summary
    summary_file = f"pls_analysis_summary_{timestamp}.json"
    with open(summary_file, 'w', encoding='utf-8') as f:
        json.dump(summary, f, indent=2, ensure_ascii=False)
    
    print(f"üìã Analysis summary: {summary_file}")

if __name__ == "__main__":
    run_pls_analysis_ref_vs_target()
