"""
PLS Workflow Template for CV Data Analysis
==========================================

- ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏Ç‡πâ‡∏°‡∏Ç‡πâ‡∏ô‡πÅ‡∏•‡∏∞‡∏≠‡∏±‡∏ï‡∏£‡∏≤‡∏Å‡∏≤‡∏£‡∏™‡πÅ‡∏Å‡∏ô
- ‡∏™‡∏∏‡πà‡∏°‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ peak ‡∏Ñ‡∏£‡∏ö‡∏ó‡∏±‡πâ‡∏á 2 ‡∏î‡πâ‡∏≤‡∏ô (‡πÉ‡∏ä‡πâ baseline detector V4)
- ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÅ‡∏•‡∏∞ gap analysis
- ‡∏™‡∏£‡πâ‡∏≤‡∏á‡πÅ‡∏•‡∏∞‡∏õ‡∏£‡∏∞‡πÄ‡∏°‡∏¥‡∏ô‡∏ú‡∏•‡πÇ‡∏°‡πÄ‡∏î‡∏• PLS
- Visualization ‡πÅ‡∏ö‡∏ö‡∏ó‡∏µ‡πà‡∏ô‡∏¥‡∏¢‡∏°‡πÉ‡∏ô‡∏á‡∏≤‡∏ô‡∏ß‡∏¥‡∏à‡∏±‡∏¢
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import json
import glob
import os
from pathlib import Path
from sklearn.cross_decomposition import PLSRegression
from sklearn.model_selection import cross_val_score, KFold
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import r2_score, mean_squared_error, mean_absolute_error
from scipy.signal import find_peaks
from scipy.integrate import trapz

# Import Enhanced Detector V4 (‡∏≠‡∏±‡∏•‡∏Å‡∏≠‡∏£‡∏¥‡∏ó‡∏∂‡∏°‡∏ó‡∏µ‡πà‡πÑ‡∏î‡πâ‡∏ú‡∏•‡πÄ‡∏Å‡∏∑‡∏≠‡∏ö 100%)
try:
    from enhanced_detector_v4 import EnhancedDetectorV4
    ENHANCED_V4_AVAILABLE = True
    print("‚úÖ Enhanced Detector V4 ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÉ‡∏ä‡πâ‡∏á‡∏≤‡∏ô")
except ImportError:
    ENHANCED_V4_AVAILABLE = False
    print("‚ö†Ô∏è  Enhanced Detector V4 ‡πÑ‡∏°‡πà‡∏û‡∏ö - ‡∏à‡∏∞‡πÉ‡∏ä‡πâ simple baseline detection")

def simple_baseline_detector(voltage, current):
    """Simple baseline detection fallback"""
    n = len(voltage)
    mid = n // 2
    
    # ‡πÉ‡∏ä‡πâ‡∏™‡πà‡∏ß‡∏ô‡πÅ‡∏£‡∏Å‡πÅ‡∏•‡∏∞‡∏™‡πà‡∏ß‡∏ô‡∏™‡∏∏‡∏î‡∏ó‡πâ‡∏≤‡∏¢ 20% ‡πÄ‡∏õ‡πá‡∏ô baseline
    baseline_region_size = n // 5
    
    forward_baseline_value = np.mean(current[:baseline_region_size])
    reverse_baseline_value = np.mean(current[-baseline_region_size:])
    
    forward_baseline = np.full(mid, forward_baseline_value)
    reverse_baseline = np.full(n - mid, reverse_baseline_value)
    
    return forward_baseline, reverse_baseline, {'method': 'simple_fallback'}

class CVPLSWorkflow:
    """
    PLS Workflow ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ baseline detector V4 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£ detect peak ‡∏ó‡∏µ‡πà‡πÅ‡∏°‡πà‡∏ô‡∏¢‡∏≥
    """
    
    def __init__(self, palmsens_dir="Test_data/Palmsens", stm32_dir="Test_data/Stm32", output_dir="pls_results"):
        self.palmsens_dir = Path(palmsens_dir)
        self.stm32_dir = Path(stm32_dir)
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        
        self.results = {
            'data_matrix': [],
            'concentrations': [],
            'scan_rates': [],
            'peak_data': {},
            'missing_combinations': []
        }
    
    def load_cv_file(self, filepath):
        """‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå CV ‡πÅ‡∏•‡∏∞ detect peaks ‡∏î‡πâ‡∏ß‡∏¢ V4"""
        try:
            # ‡πÇ‡∏´‡∏•‡∏î‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            if filepath.suffix == '.csv':
                data = pd.read_csv(filepath)
            elif filepath.suffix == '.json':
                with open(filepath, 'r') as f:
                    data = json.load(f)
                    if 'data' in data:
                        df = pd.DataFrame(data['data'])
                    else:
                        return None
            else:
                return None
            
            # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö columns ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
            if 'voltage' not in data.columns or 'current' not in data.columns:
                return None
            
            voltage = data['voltage'].values
            current = data['current'].values
            
            # ‡πÉ‡∏ä‡πâ Enhanced Detector V4 ‡∏´‡∏£‡∏∑‡∏≠ fallback
            if ENHANCED_V4_AVAILABLE:
                detector = EnhancedDetectorV4()
                # ‡πÉ‡∏ä‡πâ Enhanced V4 ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå CV ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
                results = detector.analyze_cv_data({
                    'voltage': voltage,
                    'current': current
                })
                
                # ‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏à‡∏≤‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
                if 'baseline_data' in results:
                    baseline_info = results['baseline_data']
                    forward_baseline = baseline_info.get('forward_baseline', np.zeros(len(voltage)//2))
                    reverse_baseline = baseline_info.get('reverse_baseline', np.zeros(len(voltage) - len(voltage)//2))
                    info = {'method': 'enhanced_v4', 'confidence': results.get('confidence', 0)}
                else:
                    # fallback ‡∏ñ‡πâ‡∏≤ Enhanced V4 fail
                    forward_baseline, reverse_baseline, info = simple_baseline_detector(voltage, current)
            else:
                forward_baseline, reverse_baseline, info = simple_baseline_detector(voltage, current)
            
            # ‡∏´‡∏≤ peak ‡∏´‡∏•‡∏±‡∏á‡∏à‡∏≤‡∏Å subtract baseline
            corrected_current = current - np.concatenate([forward_baseline, reverse_baseline])
            
            # Peak detection
            peaks_pos, _ = find_peaks(corrected_current, height=np.std(corrected_current))
            peaks_neg, _ = find_peaks(-corrected_current, height=np.std(corrected_current))
            
            # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì peak properties
            peak_heights = []
            peak_areas = []
            
            if len(peaks_pos) > 0:
                anodic_peak_height = np.max(corrected_current[peaks_pos])
                peak_heights.append(anodic_peak_height)
                
                # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì area ‡∏£‡∏≠‡∏ö peak
                peak_idx = peaks_pos[np.argmax(corrected_current[peaks_pos])]
                start_idx = max(0, peak_idx - 20)
                end_idx = min(len(corrected_current), peak_idx + 20)
                area = trapz(corrected_current[start_idx:end_idx], voltage[start_idx:end_idx])
                peak_areas.append(area)
            
            if len(peaks_neg) > 0:
                cathodic_peak_height = np.min(corrected_current[peaks_neg])
                peak_heights.append(abs(cathodic_peak_height))
                
                # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì area ‡∏£‡∏≠‡∏ö peak
                peak_idx = peaks_neg[np.argmin(corrected_current[peaks_neg])]
                start_idx = max(0, peak_idx - 20)
                end_idx = min(len(corrected_current), peak_idx + 20)
                area = abs(trapz(corrected_current[start_idx:end_idx], voltage[start_idx:end_idx]))
                peak_areas.append(area)
            
            return {
                'voltage': voltage,
                'current': current,
                'corrected_current': corrected_current,
                'baseline_info': info,
                'anodic_peak': peak_heights[0] if len(peak_heights) > 0 else None,
                'cathodic_peak': peak_heights[1] if len(peak_heights) > 1 else None,
                'anodic_area': peak_areas[0] if len(peak_areas) > 0 else None,
                'cathodic_area': peak_areas[1] if len(peak_areas) > 1 else None,
                'has_both_peaks': len(peak_heights) >= 2
            }
            
        except Exception as e:
            print(f"Error loading {filepath}: {e}")
            return None
    
    def extract_metadata_from_filename(self, filename):
        """‡πÅ‡∏¢‡∏Å concentration ‡πÅ‡∏•‡∏∞ scan rate ‡∏à‡∏≤‡∏Å filename ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏±‡πâ‡∏á Palmsens ‡πÅ‡∏•‡∏∞ STM32"""
        import re
        
        filename_lower = filename.lower()
        
        # Pattern ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö concentration
        concentration = None
        
        # Palmsens format: Palmsens_0.5mM_...
        conc_match = re.search(r'palmsens[_\s]*(\d+\.?\d*)\s*mm', filename_lower)
        if conc_match:
            concentration = float(conc_match.group(1))
        
        # STM32 format: Pipot_Ferro_0_5mM_... ‡∏´‡∏£‡∏∑‡∏≠ Pipot_Ferro_1_0mM_...
        if concentration is None:
            conc_match = re.search(r'pipot[_\s]*ferro[_\s]*(\d+)[_\s]*(\d+)[_\s]*mm', filename_lower)
            if conc_match:
                major = int(conc_match.group(1))
                minor = int(conc_match.group(2))
                concentration = major + minor / 10.0
        
        # General pattern: ‡πÉ‡∏î ‡πÜ ‡∏ó‡∏µ‡πà‡∏°‡∏µ mM
        if concentration is None:
            conc_match = re.search(r'(\d+\.?\d*)\s*mm', filename_lower)
            if conc_match:
                concentration = float(conc_match.group(1))
        
        # Pattern ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö scan rate
        scan_rate = None
        
        # ‡∏£‡∏π‡∏õ‡πÅ‡∏ö‡∏ö‡∏ï‡πà‡∏≤‡∏á ‡πÜ ‡∏Ç‡∏≠‡∏á scan rate: 100mVpS, 100mV/s, 100mVs, etc.
        scan_patterns = [
            r'(\d+\.?\d*)\s*mv[\/\s]*p?s',  # 100mVpS, 100mV/s, 100mVs
            r'(\d+\.?\d*)\s*mv',            # 100mV
            r'(\d+\.?\d*)\s*scan',          # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ scan ‡πÉ‡∏ô‡∏ä‡∏∑‡πà‡∏≠
        ]
        
        for pattern in scan_patterns:
            scan_match = re.search(pattern, filename_lower)
            if scan_match:
                scan_rate = float(scan_match.group(1))
                break
        
        # Debug info
        if concentration is None or scan_rate is None:
            print(f"‚ö†Ô∏è  ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏î‡πâ: {filename}")
            print(f"   Concentration: {concentration}, Scan Rate: {scan_rate}")
        
        return concentration, scan_rate

    
    def scan_data_files(self):
        """‡∏™‡πÅ‡∏Å‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• CV ‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏à‡∏≤‡∏Å Palmsens ‡πÅ‡∏•‡∏∞ STM32"""
        all_files = []
        
        # ‡∏™‡πÅ‡∏Å‡∏ô‡πÑ‡∏ü‡∏•‡πå Palmsens (reference potentiostat)
        if self.palmsens_dir.exists():
            palmsens_files = list(self.palmsens_dir.glob("**/*.csv"))
            palmsens_files.extend(list(self.palmsens_dir.glob("**/*.json")))
            for f in palmsens_files:
                all_files.append((f, 'palmsens'))
        
        # ‡∏™‡πÅ‡∏Å‡∏ô‡πÑ‡∏ü‡∏•‡πå STM32 (target potentiostat) 
        if self.stm32_dir.exists():
            stm32_files = list(self.stm32_dir.glob("**/*.csv"))
            stm32_files.extend(list(self.stm32_dir.glob("**/*.json")))
            for f in stm32_files:
                all_files.append((f, 'stm32'))
        
        print(f"üîç ‡∏û‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• {len(all_files)} ‡πÑ‡∏ü‡∏•‡πå")
        print(f"   - Palmsens: {len([f for f, t in all_files if t == 'palmsens'])} ‡πÑ‡∏ü‡∏•‡πå")
        print(f"   - STM32: {len([f for f, t in all_files if t == 'stm32'])} ‡πÑ‡∏ü‡∏•‡πå")
        
        data_matrix = []
        concentrations = set()
        scan_rates = set()
        
        for filepath, device_type in all_files:
            # ‡πÅ‡∏¢‡∏Å‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• metadata
            concentration, scan_rate = self.extract_metadata_from_filename(filepath.name)
            
            if concentration is None or scan_rate is None:
                continue
                
            # ‡πÇ‡∏´‡∏•‡∏î‡πÅ‡∏•‡∏∞‡∏ß‡∏¥‡πÄ‡∏Ñ‡∏£‡∏≤‡∏∞‡∏´‡πå‡πÑ‡∏ü‡∏•‡πå
            cv_data = self.load_cv_file(filepath)
            if cv_data is None:
                continue
            
            # ‡πÄ‡∏Å‡πá‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
            row = {
                'filename': filepath.name,
                'filepath': str(filepath),
                'device_type': device_type,
                'concentration': concentration,
                'scan_rate': scan_rate,
                'anodic_peak': cv_data['anodic_peak'],
                'cathodic_peak': cv_data['cathodic_peak'], 
                'anodic_area': cv_data['anodic_area'],
                'cathodic_area': cv_data['cathodic_area'],
                'has_both_peaks': cv_data['has_both_peaks'],
                'baseline_method': cv_data.get('baseline_info', {}).get('method', 'unknown'),
                'confidence': cv_data.get('baseline_info', {}).get('confidence', 0)
            }
            
            data_matrix.append(row)
            concentrations.add(concentration)
            scan_rates.add(scan_rate)
        
        self.results['data_matrix'] = data_matrix
        self.results['concentrations'] = sorted(concentrations)
        self.results['scan_rates'] = sorted(scan_rates)
        
        return pd.DataFrame(data_matrix)
    
    def create_data_availability_table(self):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ‡πÅ‡∏•‡∏∞‡πÑ‡∏°‡πà‡∏°‡∏µ"""
        df = pd.DataFrame(self.results['data_matrix'])
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á concentration vs scan_rate
        availability_table = []
        missing_combinations = []
        
        for conc in self.results['concentrations']:
            for scan in self.results['scan_rates']:
                subset = df[(df['concentration'] == conc) & (df['scan_rate'] == scan)]
                valid_peaks = subset[subset['has_both_peaks'] == True]
                
                if len(valid_peaks) > 0:
                    # ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡πÑ‡∏î‡πâ
                    sample = valid_peaks.iloc[0]  # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡∏ï‡∏±‡∏ß‡πÅ‡∏£‡∏Å ‡∏´‡∏£‡∏∑‡∏≠‡∏à‡∏∞ random ‡∏Å‡πá‡πÑ‡∏î‡πâ
                    availability_table.append({
                        'concentration': conc,
                        'scan_rate': scan, 
                        'available': True,
                        'filename': sample['filename'],
                        'anodic_peak': sample['anodic_peak'],
                        'cathodic_peak': sample['cathodic_peak']
                    })
                else:
                    # ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà‡∏°‡∏µ peak ‡∏Ñ‡∏£‡∏ö
                    missing_combinations.append({
                        'concentration': conc,
                        'scan_rate': scan,
                        'available': False,
                        'reason': 'No data with both peaks'
                    })
                    availability_table.append({
                        'concentration': conc,
                        'scan_rate': scan,
                        'available': False, 
                        'filename': None,
                        'anodic_peak': None,
                        'cathodic_peak': None
                    })
        
        self.results['missing_combinations'] = missing_combinations
        return pd.DataFrame(availability_table)
    
    def perform_pls_analysis(self, df_available):
        """‡∏ó‡∏≥ PLS analysis ‡∏Å‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ"""
        # ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏°‡∏µ peak ‡∏Ñ‡∏£‡∏ö
        valid_data = df_available[df_available['available'] == True].copy()
        
        if len(valid_data) < 5:
            print("‚ùå ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö PLS analysis (‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏ô‡πâ‡∏≠‡∏¢ 5 samples)")
            return None
        
        # ‡πÄ‡∏ï‡∏£‡∏µ‡∏¢‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        X = valid_data[['anodic_peak', 'cathodic_peak']].values
        y = valid_data['concentration'].values
        
        # Scaling
        scaler_X = StandardScaler()
        scaler_y = StandardScaler()
        
        X_scaled = scaler_X.fit_transform(X)
        y_scaled = scaler_y.fit_transform(y.reshape(-1, 1)).ravel()
        
        # PLS Model
        pls = PLSRegression(n_components=min(2, X.shape[1]))
        pls.fit(X_scaled, y_scaled)
        
        # Prediction
        y_pred_scaled = pls.predict(X_scaled)
        y_pred = scaler_y.inverse_transform(y_pred_scaled.reshape(-1, 1)).ravel()
        
        # Cross-validation
        cv_scores = cross_val_score(pls, X_scaled, y_scaled, cv=5, scoring='r2')
        
        # Metrics
        r2 = r2_score(y, y_pred)
        rmse = np.sqrt(mean_squared_error(y, y_pred))
        mae = mean_absolute_error(y, y_pred)
        
        results = {
            'model': pls,
            'scaler_X': scaler_X,
            'scaler_y': scaler_y,
            'X': X,
            'y': y,
            'y_pred': y_pred,
            'r2': r2,
            'rmse': rmse,
            'mae': mae,
            'cv_scores': cv_scores,
            'cv_mean': cv_scores.mean(),
            'cv_std': cv_scores.std()
        }
        
        return results
    
    def create_visualizations(self, pls_results, df_available):
        """‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏£‡∏≤‡∏ü‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•"""
        if pls_results is None:
            return
        
        fig, axes = plt.subplots(2, 2, figsize=(12, 10))
        
        # 1. Prediction vs Actual
        ax1 = axes[0, 0]
        y = pls_results['y']
        y_pred = pls_results['y_pred']
        
        ax1.scatter(y, y_pred, alpha=0.7, s=60)
        min_val, max_val = min(y.min(), y_pred.min()), max(y.max(), y_pred.max())
        ax1.plot([min_val, max_val], [min_val, max_val], 'r--', lw=2)
        ax1.set_xlabel('Actual Concentration (mM)')
        ax1.set_ylabel('Predicted Concentration (mM)')
        ax1.set_title(f'PLS Prediction vs Actual\nR¬≤ = {pls_results["r2"]:.3f}')
        ax1.grid(True, alpha=0.3)
        
        # 2. Residuals
        ax2 = axes[0, 1]
        residuals = y - y_pred
        ax2.scatter(y_pred, residuals, alpha=0.7)
        ax2.axhline(y=0, color='r', linestyle='--')
        ax2.set_xlabel('Predicted Concentration (mM)')
        ax2.set_ylabel('Residuals')
        ax2.set_title('Residual Plot')
        ax2.grid(True, alpha=0.3)
        
        # 3. PLS Loadings
        ax3 = axes[1, 0]
        loadings = pls_results['model'].x_loadings_[:, 0]
        features = ['Anodic Peak', 'Cathodic Peak']
        bars = ax3.bar(features, loadings)
        ax3.set_ylabel('Loading Value')
        ax3.set_title('PLS X-Loadings (Component 1)')
        ax3.grid(True, alpha=0.3)
        
        # ‡∏™‡∏µ bars ‡∏ï‡∏≤‡∏° sign
        for i, bar in enumerate(bars):
            if loadings[i] >= 0:
                bar.set_color('blue')
            else:
                bar.set_color('red')
        
        # 4. Data availability heatmap
        ax4 = axes[1, 1]
        
        # ‡∏™‡∏£‡πâ‡∏≤‡∏á pivot table ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö heatmap
        heatmap_data = df_available.pivot(index='concentration', 
                                        columns='scan_rate', 
                                        values='available')
        
        # ‡πÅ‡∏õ‡∏•‡∏á boolean ‡πÄ‡∏õ‡πá‡∏ô int
        heatmap_data = heatmap_data.astype(int)
        
        sns.heatmap(heatmap_data, annot=True, cmap='RdYlGn', 
                   cbar_kws={'label': 'Data Available'}, ax=ax4)
        ax4.set_title('Data Availability Matrix')
        ax4.set_xlabel('Scan Rate (mV/s)')
        ax4.set_ylabel('Concentration (mM)')
        
        plt.tight_layout()
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏π‡∏õ
        output_path = self.output_dir / f"pls_analysis_results_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}.png"
        plt.savefig(output_path, dpi=300, bbox_inches='tight')
        print(f"üíæ ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û‡∏ó‡∏µ‡πà: {output_path}")
        
        plt.show()
        
        return output_path
    
    def run_workflow(self):
        """‡∏£‡∏±‡∏ô workflow ‡∏´‡∏•‡∏±‡∏Å"""
        print("üöÄ ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô PLS Workflow ‡∏î‡πâ‡∏ß‡∏¢ Baseline Detector V4")
        print("=" * 50)
        
        # 1. ‡∏™‡πÅ‡∏Å‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        print("\nüìÇ 1. ‡∏™‡πÅ‡∏Å‡∏ô‡πÑ‡∏ü‡∏•‡πå‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• CV...")
        df_all = self.scan_data_files()
        print(f"   ‡∏û‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {len(df_all)} ‡πÑ‡∏ü‡∏•‡πå")
        
        # 2. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        print("\nüìä 2. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏≤‡∏£‡∏≤‡∏á‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Ç‡∏≠‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•...")
        df_availability = self.create_data_availability_table()
        
        available_count = len(df_availability[df_availability['available'] == True])
        total_combinations = len(self.results['concentrations']) * len(self.results['scan_rates'])
        
        print(f"   ‚úÖ ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {available_count}/{total_combinations} combinations")
        print(f"   ‚ùå ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•: {total_combinations - available_count} combinations")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ
        if self.results['missing_combinations']:
            print("\nüîç ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡∏ó‡∏µ‡πà‡∏´‡∏≤‡∏¢‡πÑ‡∏õ:")
            for missing in self.results['missing_combinations']:
                print(f"   - {missing['concentration']} mM @ {missing['scan_rate']} mV/s")
        
        # 3. ‡∏ó‡∏≥ PLS Analysis
        print("\nüß† 3. ‡∏ó‡∏≥ PLS Analysis...")
        pls_results = self.perform_pls_analysis(df_availability)
        
        if pls_results:
            print(f"   üìà R¬≤ = {pls_results['r2']:.3f}")
            print(f"   üìà RMSE = {pls_results['rmse']:.3f}")
            print(f"   üìà MAE = {pls_results['mae']:.3f}")
            print(f"   üìà CV R¬≤ = {pls_results['cv_mean']:.3f} ¬± {pls_results['cv_std']:.3f}")
        
        # 4. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏£‡∏π‡∏õ‡∏†‡∏≤‡∏û
        print("\nüìä 4. ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Å‡∏≤‡∏£‡πÅ‡∏™‡∏î‡∏á‡∏ú‡∏•...")
        self.create_visualizations(pls_results, df_availability)
        
        # 5. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå
        print("\nüíæ 5. ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå...")
        self.save_results(df_availability, pls_results)
        
        print("\n‚úÖ ‡πÄ‡∏™‡∏£‡πá‡∏à‡∏™‡∏¥‡πâ‡∏ô PLS Workflow!")
        return pls_results, df_availability
    
    def save_results(self, df_availability, pls_results):
        """‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå"""
        timestamp = pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å data availability
        availability_path = self.output_dir / f"data_availability_{timestamp}.csv"
        df_availability.to_csv(availability_path, index=False)
        
        # ‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å summary report
        report_path = self.output_dir / f"pls_report_{timestamp}.txt"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write("PLS Analysis Report\n")
            f.write("==================\n\n")
            f.write(f"Analysis Date: {pd.Timestamp.now()}\n")
            f.write(f"Method: Baseline Detector V4\n\n")
            
            f.write("Data Summary:\n")
            f.write(f"- Total concentrations: {len(self.results['concentrations'])}\n")
            f.write(f"- Total scan rates: {len(self.results['scan_rates'])}\n")
            f.write(f"- Available combinations: {len(df_availability[df_availability['available']])}\n")
            f.write(f"- Missing combinations: {len(self.results['missing_combinations'])}\n\n")
            
            if pls_results:
                f.write("PLS Results:\n")
                f.write(f"- R¬≤ = {pls_results['r2']:.3f}\n")
                f.write(f"- RMSE = {pls_results['rmse']:.3f}\n") 
                f.write(f"- MAE = {pls_results['mae']:.3f}\n")
                f.write(f"- CV R¬≤ = {pls_results['cv_mean']:.3f} ¬± {pls_results['cv_std']:.3f}\n")
        
        print(f"   üíæ Data availability: {availability_path}")
        print(f"   üíæ Report: {report_path}")


# ‡∏ß‡∏¥‡∏ò‡∏µ‡∏Å‡∏≤‡∏£‡∏£‡∏±‡∏ô
if __name__ == "__main__":
    # ‡πÉ‡∏ä‡πâ path ‡∏ó‡∏µ‡πà‡∏ñ‡∏π‡∏Å‡∏ï‡πâ‡∏≠‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• Reference (Palmsens) ‡πÅ‡∏•‡∏∞ Target (STM32)
    workflow = CVPLSWorkflow(
        palmsens_dir="Test_data/Palmsens",    # Reference potentiostat
        stm32_dir="Test_data/Stm32",          # Target potentiostat  
        output_dir="pls_results"
    )
    
    # ‡∏£‡∏±‡∏ô workflow
    pls_results, df_availability = workflow.run_workflow()
    
    if pls_results:
        print("\nüéâ PLS Analysis ‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à!")
        print(f"   R¬≤ = {pls_results['r2']:.3f}")
        print(f"   RMSE = {pls_results['rmse']:.3f} mM")
        print(f"   MAE = {pls_results['mae']:.3f} mM")
    else:
        print("\n‚ùå PLS Analysis ‡πÑ‡∏°‡πà‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à - ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÑ‡∏°‡πà‡πÄ‡∏û‡∏µ‡∏¢‡∏á‡∏û‡∏≠")
