"""
AI Dashboard Routes for H743Poten-Web
Migrated from PyPiPo Working-AI-Dashboard-V1
"""

from flask import Blueprint, render_template, jsonify, request
import sys
import os
import logging
import numpy as np
from pathlib import Path

# Configure logger
logger = logging.getLogger(__name__)

# Add current directory to path for imports
current_dir = Path(__file__).parent.parent
sys.path.insert(0, str(current_dir))

try:
    from ai.ml_models.electrochemical_intelligence import ElectrochemicalIntelligence
    from ai.ml_models.peak_classifier import PeakClassifier
    from ai.ml_models.concentration_predictor import ConcentrationPredictor
    from ai.ml_models.signal_processor import SignalProcessor
except ImportError as e:
    print(f"Warning: AI modules not available: {e}")
    import numpy as np
    
    # Create mock classes for development with more realistic data
    class ElectrochemicalIntelligence:
        def analyze_cv_data(self, data):
            voltage = np.array(data['voltage'])
            current = np.array(data['current'])
            # Generate mock peaks
            peaks = [
                {'voltage': 0.25, 'current': 2.1, 'width': 0.12, 'type': 'oxidation'},
                {'voltage': -0.15, 'current': -1.8, 'width': 0.15, 'type': 'reduction'}
            ]
            return {
                'voltage': voltage.tolist(),
                'current': current.tolist(),
                'peaks': peaks,
                'analysis': {
                    'num_peaks': len(peaks),
                    'reversibility': 0.92,
                    'peak_separation': 0.4
                }
            }
    
    class PeakClassifier:
        def classify_peaks(self, peaks):
            return {
                'classification': [
                    {'type': 'oxidation', 'confidence': 0.95},
                    {'type': 'reduction', 'confidence': 0.88}
                ],
                'accuracy': 0.958
            }
    
    class ConcentrationPredictor:
        def predict_concentration(self, data):
            return {
                'concentration': 47.3,
                'unit': 'Î¼M',
                'confidence_interval': {
                    'lower': 45.2,
                    'upper': 49.4
                },
                'r_squared': 0.994
            }
    
    class SignalProcessor:
        def enhance_signal(self, data):
            voltage = np.array(data['voltage'])
            current = np.array(data['current'])
            # Mock signal processing
            enhanced_current = current + np.random.normal(0, 0.1, len(current))
            
            return {
                'voltage': voltage.tolist(),
                'current': enhanced_current.tolist(),
                'quality': {
                    'snr_db': 35.2,
                    'baseline_drift': 0.002,
                    'noise_level': 1e-9,
                    'quality_score': 0.92,
                    'recommendations': ['Signal quality is good for quantitative analysis']
                },
                'filter_info': {
                    'method': 'Savitzky-Golay',
                    'quality_improvement': 15.2
                }
            }

# Create Blueprint
ai_bp = Blueprint('ai', __name__, url_prefix='/ai')

# Initialize AI modules
try:
    electrochemical_ai = ElectrochemicalIntelligence()
    peak_classifier = PeakClassifier()
    concentration_predictor = ConcentrationPredictor()
    signal_processor = SignalProcessor()
except Exception as e:
    print(f"Warning: Failed to initialize AI modules: {e}")
    # Use mock instances
    electrochemical_ai = ElectrochemicalIntelligence()
    peak_classifier = PeakClassifier()
    concentration_predictor = ConcentrationPredictor()
    signal_processor = SignalProcessor()

@ai_bp.route('/')
@ai_bp.route('/dashboard')
def ai_dashboard():
    """Main AI Dashboard page"""
    return render_template('ai_dashboard.html')

@ai_bp.route('/api/analyze', methods=['POST'])
def analyze_data():
    """Analyze electrochemical data using AI"""
    try:
        print("Received analyze request")  # Debug log
        data = request.get_json()
        print(f"Request data type: {type(data)}")  # Debug log type
        print(f"Request data: {data}")  # Debug log data
        print(f"Request headers: {request.headers}")  # Debug log headers
        
        if not data:
            print("No data received")  # Debug log
            return jsonify({
                'success': False,
                'error': 'No data provided'
            }), 400
        
        if 'voltage' not in data or 'current' not in data:
            print(f"Missing required fields. Got: {list(data.keys())}")  # Debug log
            return jsonify({
                'success': False,
                'error': 'Invalid data format. Expected voltage and current arrays.'
            }), 400
        
        print("Performing AI analysis")  # Debug log
        
        # 1. Enhance signal
        enhanced_signal = signal_processor.enhance_signal({
            'signal': data['current']
        })
        
        # 2. Find peaks
        analyzed_data = electrochemical_ai.analyze_cv_data(data)
        
        # 3. Classify peaks
        peak_types = peak_classifier.classify_peaks(analyzed_data['peaks'])
        
        # 4. Predict concentration from peaks
        concentration_result = concentration_predictor.predict_concentration({
            'peaks': analyzed_data['peaks']
        })
        
        # Combine results
        result = {
            'voltage': data['voltage'],
            'current': enhanced_signal['signal'],
            'peaks': analyzed_data['peaks'],
            'analysis': {
                'num_peaks': len(analyzed_data['peaks']),
                'peak_types': peak_types['classification'],
                'classification_accuracy': peak_types['accuracy'],
                'concentration': concentration_result.predicted_concentration,
                'confidence_interval': concentration_result.confidence_interval,
                'signal_quality': enhanced_signal['quality']
            }
        }
        
        print("Analysis complete")  # Debug log
        return jsonify({
            'success': True,
            'analysis': result
        })
        
    except Exception as e:
        import traceback
        print(f"Error in analyze_data: {str(e)}")  # Debug log
        print(traceback.format_exc())  # Print full traceback
        return jsonify({
            'success': False,
            'error': f'Analysis failed: {str(e)}'
        }), 500

@ai_bp.route('/api/analyze-peaks', methods=['POST'])
def analyze_peaks():
    """Detect and classify peaks in electrochemical data"""
    logger.info("=== START ANALYZE PEAKS ===")
    logger.info(f"Request Headers: {request.headers}")
    
    try:
        data = request.get_json()
        logger.info(f"Received data type: {type(data)}")
        logger.info(f"Data keys: {list(data.keys()) if isinstance(data, dict) else 'Not a dict'}")
        logger.info(f"Raw request data: {data}")
        
        if not data:
            logger.error("No data provided in request")
            return jsonify({
                'success': False,
                'error': 'No data provided'
            }), 400
        
        if 'voltage' not in data or 'current' not in data:
            logger.error(f"Missing required fields. Got: {list(data.keys())}")
            return jsonify({
                'success': False,
                'error': 'Invalid data format. Expected voltage and current arrays.'
            }), 400
        
        logger.info(f"Voltage data length: {len(data['voltage'])}")
        logger.info(f"Current data length: {len(data['current'])}")
        logger.info(f"Voltage sample: {data['voltage'][:5]}")
        logger.info(f"Current sample: {data['current'][:5]}")
        
        # Extract peaks from the voltammogram data
        logger.info("Starting peak extraction...")
        try:
            extracted_peaks = peak_classifier.extract_features(
                np.array(data['voltage']), 
                np.array(data['current']), 
                peak_indices=[]  # Will be detected automatically
            )
            logger.info(f"Extracted {len(extracted_peaks)} peaks")
            
            # Classify the detected peaks
            logger.info("Starting peak classification...")
            peak_classifications = peak_classifier.classify_peaks(extracted_peaks)
            logger.info(f"Classified {len(peak_classifications)} peaks")
            
            # Format response
            response = {
                'success': True,
                'peaks': [
                    {
                        'voltage': peak.potential,
                        'current': peak.height,
                        'width': peak.width,
                        'type': classification.peak_type,
                        'confidence': classification.confidence
                    }
                    for peak, classification in zip(extracted_peaks, peak_classifications)
                ]
            }
            logger.info("Peak analysis completed successfully")
            return jsonify(response)
            
        except Exception as e:
            error_msg = f"Error in peak analysis: {str(e)}"
            logger.error(error_msg)
            logger.error(f"Peak classifier state: {peak_classifier.get_model_info()}")
            return jsonify({
                'success': False,
                'error': error_msg
            }), 500
            
    except Exception as e:
        error_msg = f"Error processing request: {str(e)}"
        logger.error(error_msg)
        return jsonify({
            'success': False,
            'error': error_msg
        }), 500        # Classify the detected peaks
        classifications = peak_classifier.classify_peaks(peaks)
        
        return jsonify({
            'success': True,
            'peaks': [
                {
                    'voltage': peak.potential,
                    'current': peak.height,
                    'width': peak.width,
                    'type': classification.peak_type,
                    'confidence': classification.confidence
                }
                for peak, classification in zip(peaks, classifications)
            ]
        })
        
    except Exception as e:
        logger.error(f"Peak analysis failed: {str(e)}")
        return jsonify({
            'success': False,
            'error': f'Peak analysis failed: {str(e)}'
        }), 500

@ai_bp.route('/api/classify-peaks', methods=['POST'])
def classify_peaks():
    """Classify peaks in electrochemical data"""
    try:
        data = request.get_json()
        
        if not data or 'peaks' not in data:
            return jsonify({
                'success': False,
                'error': 'Invalid data format. Expected peaks array.'
            }), 400
        
        # Classify peaks
        classification = peak_classifier.classify_peaks(data['peaks'])
        
        return jsonify({
            'success': True,
            'classification': classification
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'Peak classification failed: {str(e)}'
        }), 500

@ai_bp.route('/api/predict-concentration', methods=['POST'])
def predict_concentration():
    """Predict analyte concentration"""
    try:
        print("\n=== PREDICT CONCENTRATION ENDPOINT ===")
        print("1. Getting request data...")
        data = request.get_json()
        print(f"Request data type: {type(data)}")
        print(f"Request keys: {list(data.keys()) if isinstance(data, dict) else 'Not a dict'}")
        print(f"Raw request data: {data}")
        print(f"Content-Type: {request.headers.get('Content-Type')}")
        
        # Validate required fields
        print("\n2. Validating request data...")
        if not data or not isinstance(data, dict):
            print("Error: Invalid data format - not a dict")
            return jsonify({
                'success': False,
                'error': 'Invalid request data. Expected JSON object.'
            }), 400
            
        print("\n3. Checking required fields...")
        if 'peaks' not in data:
            print(f"Error: Missing required field 'peaks'. Available keys: {list(data.keys())}")
            return jsonify({
                'success': False,
                'error': 'Missing required field: peaks array'
            }), 400
            
        print("\n4. Validating peaks data...")
        if not isinstance(data['peaks'], list):
            print(f"Error: Invalid type - peaks must be an array")
            return jsonify({
                'success': False,
                'error': 'Peaks must be an array'
            }), 400
            
        print("\n5. Validating peaks format...")
        for i, peak in enumerate(data['peaks']):
            if not isinstance(peak, dict):
                print(f"Error: Peak {i} is not an object")
                return jsonify({
                    'success': False,
                    'error': f'Peak {i} must be an object with voltage, current, and width properties'
                }), 400
                
            required_fields = ['voltage', 'current', 'width']
            missing_fields = [field for field in required_fields if field not in peak]
            if missing_fields:
                print(f"Error: Peak {i} missing fields: {missing_fields}")
                return jsonify({
                    'success': False,
                    'error': f'Peak {i} missing required fields: {", ".join(missing_fields)}'
                }), 400
            
        # Predict concentration using the full data
        print("\n6. Processing concentration prediction...")
        print("Input peaks data:")
        print(f"Number of peaks: {len(data['peaks'])}")
        print(f"Peaks data: {data['peaks']}")
        
        result = concentration_predictor.predict_concentration({
            'peaks': data['peaks']
        })
        
        print("\n7. Prediction complete")
        print("Result structure:")
        print(f"Result: {result}")
        
        return jsonify({
            'success': True,
            'result': result
        })
        
    except Exception as e:
        import traceback
        print(f"Error in predict_concentration: {str(e)}")
        print(traceback.format_exc())
        return jsonify({
            'success': False,
            'error': f'Concentration prediction failed: {str(e)}'
        }), 500

@ai_bp.route('/api/enhance-signal', methods=['POST'])
def enhance_signal():
    """Enhance signal quality using AI"""
    try:
        print("\n=== ENHANCE SIGNAL ENDPOINT ===")
        print("1. Getting request data...")
        data = request.get_json()
        print(f"Request data type: {type(data)}")
        print(f"Request keys: {list(data.keys()) if isinstance(data, dict) else 'Not a dict'}")
        print(f"Raw request data: {data}")
        print(f"Content-Type: {request.headers.get('Content-Type')}")
        
        # Validate required fields
        print("\n2. Validating request data...")
        if not data or not isinstance(data, dict):
            print("Error: Invalid data format - not a dict")
            return jsonify({
                'success': False,
                'error': 'Invalid request data. Expected JSON object.'
            }), 400
            
        if 'signal' not in data:
            print(f"Error: Missing required field 'signal'. Available keys: {list(data.keys())}")
            return jsonify({
                'success': False,
                'error': 'Missing required field: signal array'
            }), 400
            
        print("\n3. Validating array type...")
        signal_type = type(data['signal'])
        print(f"Signal type: {signal_type}")
        
        if not isinstance(data['signal'], list):
            print(f"Error: Invalid type - signal: {signal_type}")
            return jsonify({
                'success': False,
                'error': 'Signal must be an array'
            }), 400
            
        print("\n4. Validating array length...")
        signal_len = len(data['signal'])
        print(f"Signal length: {signal_len}")
        
        if signal_len == 0:
            print("Error: Empty signal array")
            return jsonify({
                'success': False,
                'error': 'Signal array cannot be empty'
            }), 400
            
        # Enhance signal with the provided data
        print("\n5. Processing signal...")
        print("Input data sample:")
        print(f"Signal (first 5): {data['signal'][:5] if len(data['signal']) > 5 else data['signal']}")
        
        result = signal_processor.enhance_signal({
            'signal': data['signal']
        })
        
        print("\n6. Processing complete")
        print("Result structure:")
        print(f"Keys in result: {list(result.keys())}")
        print(f"Quality metrics: {result.get('quality', {})}")
        
        return jsonify({
            'success': True,
            'result': result
        })
        
    except Exception as e:
        import traceback
        print(f"Error in enhance_signal: {str(e)}")
        print(traceback.format_exc())
        return jsonify({
            'success': False,
            'error': f'Signal enhancement failed: {str(e)}'
        }), 500

@ai_bp.route('/api/status')
def ai_status():
    """Get AI system status"""
    try:
        status = {
            'ai_modules_loaded': True,
            'electrochemical_ai': 'available',
            'peak_classifier': 'available',
            'concentration_predictor': 'available',
            'signal_processor': 'available',
            'version': '2.0.0',
            'last_updated': '2025-08-14'
        }
        
        return jsonify({
            'success': True,
            'status': status
        })
        
    except Exception as e:
        return jsonify({
            'success': False,
            'error': f'Status check failed: {str(e)}'
        }), 500
