#!/usr/bin/env python3
"""
Data Processing Status Survey
‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• - ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î vs ‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô database
"""

import sqlite3
import os
import glob
from datetime import datetime
import json

def survey_data_status():
    """‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•"""
    
    print("üìä Data Processing Status Survey")
    print("=" * 60)
    
    # 1. ‡∏ô‡∏±‡∏ö‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡πÉ‡∏ô Test_data
    test_data_patterns = [
        "Test_data/**/*.csv",
        "Test_data/**/*.txt"
    ]
    
    all_files = []
    for pattern in test_data_patterns:
        files = glob.glob(pattern, recursive=True)
        all_files.extend(files)
    
    print(f"üìÅ Total CSV/TXT files in Test_data: {len(all_files)}")
    
    # Group by subdirectory
    dir_count = {}
    for file in all_files:
        dir_name = os.path.dirname(file).split(os.sep)[1] if os.sep in file else "root"
        dir_count[dir_name] = dir_count.get(dir_name, 0) + 1
    
    print("üìÇ Files by directory:")
    for dir_name, count in sorted(dir_count.items()):
        print(f"   {dir_name}: {count} files")
    
    # 2. ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÉ‡∏ô database
    db_path = "data_logs/parameter_log.db"
    
    if not os.path.exists(db_path):
        print(f"‚ùå Database not found: {db_path}")
        return
    
    try:
        conn = sqlite3.connect(db_path)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö tables
        cursor.execute("SELECT name FROM sqlite_master WHERE type='table'")
        tables = [row[0] for row in cursor.fetchall()]
        print(f"\nüóÉÔ∏è  Database tables: {', '.join(tables)}")
        
        # ‡∏ô‡∏±‡∏ö records ‡πÉ‡∏ô‡πÅ‡∏ï‡πà‡∏•‡∏∞ table
        for table in tables:
            if table != 'sqlite_sequence':
                cursor.execute(f"SELECT COUNT(*) FROM {table}")
                count = cursor.fetchone()[0]
                print(f"   {table}: {count} records")
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö measurements table - ‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏ú‡πà‡∏≤‡∏ô Web UI ‡πÅ‡∏•‡πâ‡∏ß
        cursor.execute("SELECT DISTINCT file_path FROM measurements WHERE file_path IS NOT NULL")
        processed_files = [row[0] for row in cursor.fetchall()]
        print(f"\n‚úÖ Files processed through Web UI: {len(processed_files)}")
        
        # ‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á processed files
        if processed_files:
            print("üìã Sample processed files:")
            for i, file_path in enumerate(processed_files[:5]):
                print(f"   {i+1}. {file_path}")
            if len(processed_files) > 5:
                print(f"   ... and {len(processed_files) - 5} more")
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö peak_parameters table
        cursor.execute("SELECT COUNT(*) FROM peak_parameters")
        peak_count = cursor.fetchone()[0]
        print(f"\nüéØ Total peak parameters detected: {peak_count}")
        
        # ‡∏î‡∏π sample IDs ‡πÅ‡∏•‡∏∞‡∏à‡∏≥‡∏ô‡∏ß‡∏ô peaks
        cursor.execute("""
            SELECT sample_id, COUNT(*) as peak_count 
            FROM peak_parameters 
            GROUP BY sample_id 
            ORDER BY sample_id
        """)
        sample_peaks = cursor.fetchall()
        print(f"\nüìä Peak data by Sample ID:")
        for row in sample_peaks:
            print(f"   {row['sample_id']}: {row['peak_count']} peaks")
        
        # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏¢‡∏±‡∏á‡πÑ‡∏°‡πà‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•
        unprocessed_count = len(all_files) - len(processed_files)
        print(f"\n‚è≥ Files NOT processed yet: {unprocessed_count}")
        print(f"üìà Processing progress: {len(processed_files)}/{len(all_files)} ({len(processed_files)/len(all_files)*100:.1f}%)")
        
        # ‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö peak types
        cursor.execute("""
            SELECT peak_type, COUNT(*) as count 
            FROM peak_parameters 
            GROUP BY peak_type
        """)
        peak_types = cursor.fetchall()
        print(f"\nüîç Peak types detected:")
        for row in peak_types:
            print(f"   {row['peak_type']}: {row['count']} peaks")
        
        conn.close()
        
        # ‡∏™‡∏£‡∏∏‡∏õ
        print("\n" + "=" * 60)
        print("üìã SUMMARY:")
        print(f"   Total files: {len(all_files)}")
        print(f"   Processed: {len(processed_files)}")
        print(f"   Remaining: {unprocessed_count}")
        print(f"   Peak data: {peak_count} parameters")
        print(f"   Sample IDs: {len(sample_peaks)}")
        
        if peak_count > 0:
            print("\n‚úÖ Ready for PLS analysis with existing peak data")
        else:
            print("\n‚ö†Ô∏è  No peak data available for PLS analysis")
        
        if unprocessed_count > 2000:
            print(f"üí° Suggestion: Create batch processing for {unprocessed_count} remaining files")
        
    except Exception as e:
        print(f"‚ùå Database error: {e}")

def show_sample_peak_data():
    """‡πÅ‡∏™‡∏î‡∏á‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• peak ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö PLS"""
    
    db_path = "data_logs/parameter_log.db"
    
    try:
        conn = sqlite3.connect(db_path)
        conn.row_factory = sqlite3.Row
        cursor = conn.cursor()
        
        print("\n" + "=" * 60)
        print("üéØ Sample Peak Data for PLS Analysis")
        print("=" * 60)
        
        # ‡∏î‡∏π‡πÇ‡∏Ñ‡∏£‡∏á‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏• peak
        cursor.execute("PRAGMA table_info(peak_parameters)")
        columns = cursor.fetchall()
        print("üìã Peak parameters table structure:")
        for col in columns:
            print(f"   {col['name']}: {col['type']}")
        
        # ‡∏î‡∏π‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•
        cursor.execute("""
            SELECT * FROM peak_parameters 
            LIMIT 3
        """)
        samples = cursor.fetchall()
        
        if samples:
            print(f"\nüìä Sample peak data (first 3 records):")
            for i, row in enumerate(samples, 1):
                print(f"\n   Record {i}:")
                for key in row.keys():
                    print(f"     {key}: {row[key]}")
        
        conn.close()
        
    except Exception as e:
        print(f"‚ùå Error showing sample data: {e}")

if __name__ == "__main__":
    survey_data_status()
    show_sample_peak_data()